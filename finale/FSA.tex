\documentclass[12pt]{report}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[italian]{babel}
\usepackage{bytefield}
\usepackage{cancel}
\usepackage{embedall}\embedfile{\jobname.tex}
\usepackage[bookmarks]{hyperref}
\usepackage{listings}
\usepackage[scr=rsfs]{mathalpha}
\usepackage{siunitx}
\usepackage{tabularray}
\usepackage{tcolorbox}
\usepackage{tikz}\usetikzlibrary{automata, decorations.text, patterns}
\usepackage{todonotes}
\usepackage{xcolor}

\newtheorem{teorema}{Teorema}
\newtheorem{corollario}{Corollario}
\newtheorem{proposizione}{Proposizione}
\newtheorem{proprietà}{Proprietà}
\newtheorem{lemma}{Lemma}
\newtheorem{fatto}{Fatto}
\newtheorem{definizione}{Definizione}
\newtheorem{nota}{Nota}

\renewcommand\qedsymbol{$\blacksquare$}

\usepackage{teolang}

\definecolor{codegray}{gray}{0.95}

\lstdefinestyle{mystyle}{
  numberstyle=\tiny,
  basicstyle=\footnotesize,
  breaklines=true,
  numbers=left,
  numbersep=5pt,
}
\lstset{style=mystyle}

\overfullrule=0.2cm
\begin{document}
\tableofcontents
\newpage

\chapter{Intro}
Studieremo dei sistemi particolari (macchine/grammatiche) e il loro comportamento (il linguaggio descritto) e le risorse utilizzate (risorse utilizzate, risorse per trasformazioni da una macchina e l'altra, \dots). 

\section{Terminologia}
Quando si parla di un linguagio ci sono due aspetti fondamentali:
\begin{itemize}
	\item sintassi, formata da
	\begin{itemize}
		\item i segni o simboli utilizzati
		\item le regole che ci permettono di combinarli
	\end{itemize}
	\item semantica, il processo che associa alle frasi del linguaggio un significato
\end{itemize}

Noi ci occuperemo principalmente di sintassi.

In ambito linguistico nel 1956 Chomsky introduce le grammatiche formali.
Questi sono degli oggetti matematici, il cui scopo originale era descrivere in modo rigoroso la grammatica dell'inglese.
Nello stesso periodo si stava sviluppando l'idea di compilatore, specificamente il compilatore Fortran.
Si vide che il modello proposto da Chomksy era adatto per formalizzare i linguaggi di programmazione.

Definiamo
\begin{itemize}
	\item l'alfabeto ($\Sigma$) è un insieme finito non vuoto di simboli, e.g. 
		$$ \Sigma = \{ a , b , c \} $$
	\item una stringa o parola è una sequenza di simboli sull'alfabeto.
		La sua lunghezza è definita come il numero di simboli che la compongono
		$$ | abc | = 3 $$
		Tra tutte le parole abbiamo una parola speciale, che è la parola vuota costituita da zero simboli.
		Questa è indicata con $\epsilon$ (alcuni la indicano con $\lambda$ o $\Lambda$).
		La lunghezza di questa è 0.

		Sia $a \in \Sigma$ e $x \in \Sigma^*$, definiamo 
		$$ \#_a(x) : \Sigma \times \Sigma^* \mapsto \mathbb{N} $$
		come il numero di $a$ in $x$.
	\item indichiamo l'insieme di tutte le possibili stringhe sull'alfabeto $\Sigma$ con $\Sigma^*$.
		Queste sono enumerabili.

		Chiamiamo $\Sigma^n$ l'insieme di tutte le stringhe di $n$ lettere sull'alfabeto $\Sigma$.
		% non esattamente
	\item definiamo un'operazione 
		$$ - \cdot - : \Sigma^* \times \Sigma^* \mapsto \Sigma^*$$
		come la concatenazione o prodotto di due stringhe.
		Ad esempio
		\begin{align*}
			x &= abbac \\
			y &= ca \\
			xy &= abbacca \\
			yx &= caabbac
		\end{align*}
		La parola vuota $\epsilon$ è l'identità sia destra che sinistra di questa operazione.
		L'operazione è associativa ma non commutativa.
		La struttura $\langle \Sigma^*, \cdot, \epsilon \rangle$ è detto monoide libero generato dall'alfabeto $\Sigma$.
	\item data una stringa $x \in \Sigma^*$ diciamo che $y$ è prefisso di $x$ se
		$$ \exists z \in \Sigma^* \mid x = yz $$
		Una stringa ha un numero di prefissi pari alla sua lunghezza + 1.
		$y$ è prefisso proprio di $x$ se è prefisso e non è $\epsilon$.
		Similmente definiamo il suffisso di una parola $x$, quindi $y$ è suffisso di $x$ se 
		$$ \exists x \in \Sigma^* \mid x = zy $$
		Infine diciamo che $y$ è fattore di $x$ se
		$$ \exists z, w \in \Sigma^* \mid x = zyw $$
		I prefissi e i suffissi sono particolari tipi di fattori.
		Ogni parola ha all'incirca $\frac{n^2}{2}$ fattori, infatti è facile notare che $x = aaaa$ ha diversi fattori uguali.

		Una sottosequenza di solito è una serie di elementi scelti da una parola, quindi un fattore può essere definito come una sottosequenza contigua. 
		Ad esmepio una sottosequenza di $x = abbac$ può essere $abc$.
		Sottostringa e sottoparola di solito sono sinonimi di fattore, ma a volte possono essere utilizzate come sinonimo di sottosequenza.
	\item un linguaggio $L$ è definito come un qualunque sottoinsieme di $\Sigma^*$.
		Abbiamo alcuni linguaggi particolari:
		\begin{itemize}
			\item il linguaggio vuoto $L = \varnothing$
			\item il linguaggio della parola vuota $L = \{ \epsilon \}$
			\item il linguaggio pieno $L = \Sigma^*$
		\end{itemize}
\end{itemize}

Ad esempio definiamo il linguaggio delle parole che finiscono con due $a$ come
$$ L = { w \in \Sigma^* \mid \exists y \in \Sigma^* w = yaa } $$
quindi con un insieme finito di simboli siamo risuciti a rappresentare un insieme infinito.
Questo tipo di descrizione è detta \textit{dichiarativa}.

% Definiamo l'alfabeto $\Sigma = { 0, 1, \dots, 9 }$, e definiamo $L$ come tutte le sequenze formate da 3 cifre decimali che appaiono consecutivamente nella rappresentazione del $\pi$ greco.
% embé?
In altri casi utilizzeremo delle descrizioni:
\begin{itemize}
	\item \textit{generative}: si fornisce un insieme di regole che permette di costruire tutte le possibili stringhe del linguaggio, ad esempio le grammatiche
	\item \textit{riconoscitive}: si fornisce un riconoscitore che riceve una stringa $x$ e risponde alla domanda $x \overset{?}{\in} L$, in alcuni casi queste macchine si limitano a dire sì se la stringa appartiene o non terminare in altro caso
\end{itemize}

\begin{fatto}
	Non tutti i linguaggi si possono descrivere in maniera finita, infatti le descrizioni finite sono numerabili, mentre i linguaggi no.
\end{fatto}

\begin{tcolorbox}
 	Prendiamo come alfabeto $\Sigma = \{ (, ) \}$, vogliamo descrivere $L$ l'insieme delle sequenze di parentesi bilanciate correttamente.
 	Definiamo la rappresentazione generativa che genera $L_G$:
 	\begin{enumerate}
 		\item $\epsilon \in L_G$
 		\item se $x \in L_G$ allora $(x) \in L_G$
 		\item se $x, y \in L_G$ allora $xy \in L_G$
 	\end{enumerate}
 
 	E definiamo un riconoscitore, che riconosca $L_R$:
 	\begin{itemize}
 		\item il numero di aperte deve essere uguale al numero di chiuse, quindi $\#_((x) = \#_)(x)$
 		\item per ogni prefisso il numero di parentesi aperte è maggiore o uguale del numero di chiuse, quindi per $y$ prefisso $\#_((y) \geq \#_)(y)$.
	\end{itemize}
 	Questo può essere generato come un automa con contatore.
 
 	Si può dimostrare che questi due definiscono lo stesso linguaggio. % da fare
\end{tcolorbox}

\begin{tcolorbox}
	Ora prendiamo l'alfabeo $\Sigma = \{(, ), [, ]\}$, e definiamo $L$ come il linguaggio delle sequenze di parentesi bilanciate correttamente.
	Definiamo la rappresentazione generativa che genera $L_G$:
	\begin{enumerate}
		\item $\epsilon \in L_G$
		\item se $x \in L_G$ allora $(x) \in L_G$ e $[x] \in L_G$
		\item se $x, y \in L_G$ allora $xy \in L_G$
	\end{enumerate}

	E definiamo un riconoscitore, che riconosca $L_R$:
	\begin{itemize}
		\item il numero di aperte deve essere uguale al numero di chiuse, quindi $\#_((x) = \#_)(x)$ e $\#_[(x) = \#_](x)$
		\item si utilizza una pila in cui si mette ogni parentesi aperta e si toglie quando si trova una parentesi chiusa nel caso corrisponda
	\end{itemize}
	Quindi un automa a pila.

	In alcuni casi è più facile definire come si genera, e in altri come riconoscere.
\end{tcolorbox}

\chapter{Grammatiche}
Una grammatica è una quadrupla $\langle V, \Sigma, P, S \rangle$, dove
\begin{itemize}
	\item $V$ è l'insieme finito e non vuoto delle variabili, questi vengono anche chiamate non terminali.
		Questo lo possiamo chiamare anche l'alfabeto delle variabili.
	\item $\Sigma$ è l'insieme finito e non vuoto dei termianli, o anche alfabeto dei terminali.
	\item $P$ è l'insieme finito delle regole di produzione.
		Queste sono della forma
		$$ \alpha \rightarrow \beta $$
		con $\alpha \in (V \cup \Sigma)^+$ e $\beta \in (V \cup \Sigma)^*$.
	\item $S$ è un elemento di $V$ che chiamiamo simbolo iniziale o assioma.
\end{itemize}
Per $x, y \in (V \cup \Sigma)^*$, diciamo che $x$ deriva $y$, indicato con $x \Rightarrow y$ (opzionalmente indicando la grammatica $x \underset{G}{\Rightarrow} y$), se e solo se 
$$ \exists (\alpha \rightarrow \beta) \in P, \exists \eta, \delta \in (V \cup \Sigma)^* \mid x = \eta \alpha \delta \wedge y = \eta \beta \delta $$
Inoltre diciamo che $x$ deriva $y$ in $k$ passi, con $k \in \mathbb{N}$, indicato $x \overset{k}{\Rightarrow} y$, se e solo se
$$ \exists x_0, x_1, \dots, x_k \mid x_0 = x \wedge x_k = y \wedge \forall i \in 1, \dots, k x_{i-1} \Rightarrow x_i $$
Infine diciamo che $x$ deriva $y$ in un certo numero di passi, indicato con $x \overset{*}{\Rightarrow} y$, se e solo se
$$ \exists k \geq 0 \mid x \overset{k}{\Rightarrow} y $$
e che $x$ deriva $y$ in almeno un passo, indicato con $x \overset{+}{\Rightarrow} y$, se e solo se
$$ \exists k > 0 \mid x \overset{k}{\Rightarrow} y $$

Definiamo il linguaggio generato dalla grammatica $G$ 
$$L(G) = \{ w \in \Sigma^* \mid S \overset{*}{\Rightarrow} w \} $$

Una stringa di terminali e non terminali è detta \textit{forma sentenziale}.

Due grammatiche $G_1$ e $G_2$ sono equivalenti se e solo se $L(G_1) = L(G_2)$.

\begin{tcolorbox}% [breakable]
	Sia $\Sigma = \{ (, ) \}$.
	Costruiamo $V$, inizialmente contentente solo $S$.
	Ora la sequenza vuota è bilanciata, quindi $S \rightarrow \epsilon$.
	Una sequenza di parentesi bilanciata rimane bilanciata se inserita tra due parentesi, quindi $S \rightarrow (S)$.
	Infine la concatenazione di due sequenze bilanciate è ancora bilanciata, quindi $S \rightarrow S S $.

	Ad esempio 
	\begin{align*}
		S &\Rightarrow ( S ) \\
		  &\Rightarrow ( ( S ) ) \\
		  &\Rightarrow ( ( S S ) ) \\
		  &\Rightarrow ( ( ( S ) S ) ) \\
		  &\Rightarrow ( ( ( S ) ( S ) ) ) \\
		  &\Rightarrow ( ( ( ) ( S ) ) ) \\
		  & \Rightarrow ( ( ( ) ( ) ) ) 
	\end{align*}
\end{tcolorbox}

\begin{tcolorbox}
	Data la grammatica $\langle \{S, B\}, \{a, b, c\}, P, S \rangle$, con $P$
	\begin{align*}
		S &\rightarrow a B S c \\
		S &\rightarrow a b c \\
		B a &\rightarrow a B \\
		B b &\rightarrow b b 
	\end{align*}
	Eseguiamo una derivazione
	\begin{align*}
		S &\Rightarrow a B S c \\
		  &\Rightarrow a B a b c c \\
		  &\Rightarrow a a B b c c \\
		  &\Rightarrow a a b b c c \\
		S &\Rightarrow a B S c \\
		  &\Rightarrow a B a B S c c \\
		  &\Rightarrow a a B B S c c \\
		  &\Rightarrow a a B B a b c c c \\
		  &\Rightarrow a a B a B b c c c \\
		  &\Rightarrow a a a B B b c c c \\
		  &\Rightarrow a a a B b b c c c \\
		  &\Rightarrow a a a b b b c c c
	\end{align*}
	Si può dimostrare che il linguaggio generato da questa grammatica è $L = {a^nb^nc^n \mid n > 0 }$.
\end{tcolorbox}

Le grammatiche sono classificate in base alla forma delle produzioni, possiamo definire quattro tipi di grammatiche:
\begin{center}
\begin{tblr}{|c|c|c|}
	\hline
	tipo 0 & \parbox{0.6\textwidth}{nessuna restrizione} &  \\
	\hline
	tipo 1 & \parbox{0.6\textwidth}{Se $\alpha \rightarrow \beta$ è una produzione, allora $|\beta| \geq |\alpha|$. Equivalentemente una grammatica in cui tutte le produzioni sono della forma $\alpha_1 A \alpha_2 \rightarrow \alpha_1 \beta \alpha_2$ dove $\alpha_1, \alpha_2 \in (V \cup \Sigma)^*, A \in V, \beta \in (V \cup \Sigma)^+$} & \parbox{0.2\textwidth}{anche dette context sensitive o dipendenti da contensto} \\
	\hline
	tipo 2 & \parbox{0.6\textwidth}{Se $\alpha \rightarrow \beta \in P$, allora $\alpha \in V$ e $\beta \in (V \cup \Sigma)^+$} & \parbox{0.2\textwidth}{contenxt free o libere da contesto} \\
	\hline
	tipo 3 & \parbox{0.6\textwidth}{Possiamo avere produzioni solo della forma $A \rightarrow \alpha B$ o $A \rightarrow \alpha$, con $A, B \in V, \alpha \in \Sigma$} & \parbox{0.2\textwidth}{grammatiche regolari}  \\
	\hline
\end{tblr}
\end{center}
Ogni grammatica restringe il livello precedente

\todo{Sistemo}
\begin{center}
	\begin{tikzpicture}
		\node[rectangle, fill=white!80] at (4.5cm, 3cm) {\tiny \ Tipo 0\ };
		\draw[pattern={north east lines}, pattern color=gray] (-5cm, -3.5cm) rectangle (5cm, 3.5cm);
 		\draw[ postaction={ decoration={ text effects along path
 		                               , text={\tiny \ Tipo 1\ }
 				               , text align=right
 				               , reverse path
 				               , text effects/.cd
 				               , text along path, every character/.style={fill=white, yshift=-0.5ex} 
 					       }
 				  , decorate 
				  }, fill=white] (0, 0) ellipse (4cm and 3cm);
 		\draw[ postaction={ decoration={ text effects along path
 		                               , text={\tiny \ Tipo 2\ }
 				               , text align=right
 				               , reverse path
 				               , text effects/.cd
 				               , text along path, every character/.style={fill=white, yshift=-0.5ex} 
 					       }
 				  , decorate 
				  }, fill=white] (0, 0) ellipse (3cm and 2cm);
 		\draw[ postaction={ decoration={ text effects along path
 		                               , text={\tiny \ Tipo 3\ }
 				               , text align=right
 				               , reverse path
 				               , text effects/.cd
 				               , text along path, every character/.style={fill=white, yshift=-0.5ex} 
 					       }
 				  , decorate 
 				  }, fill=white] (0, 0) ellipse (2cm and 1cm);
	\end{tikzpicture}
\end{center}

\section{Classificazione dei linguaggi}
Sia $\mathscr{L} \subseteq \Sigma^*$, diciamo che $\mathscr{L}$ è di tipo $0 \leq i \leq 3$, se e solo se $\exists G$ di tipo $i$ tale che $\mathscr{L} = L(G)$.
Questa classificazione genera una gerachia dei linguaggi, detta gerarchia di Chomksy, e chiamiamo
\begin{itemize}
	\item i linguaggi di tipo 3 come linguaggi regolari
	\item i linguaggi di tipo 2 come linguaggi conxtext free o CF
	\item i linguaggi di tipo 1 come linguaggi context sensitive o CS
	\item i linguaggi di tipo 0 come linguaggi ricorsivamente enumerabili (RE) o semidecibili
\end{itemize}

E per ognuna di queste classi esiste un modello di macchina riconoscitrice:
\begin{itemize}
	\item per i linguaggi di tipo 3 sono gli automi a stati finiti
	\item per i linguaggi di tipo 2 sono gli automi a pila
	\item per i linguaggi di tipo 1 sono gli automi limitati linearmente, questi hanno un nastro finito che possono modificare
	\item per i linguaggi di tipo 0 sono le macchine di Turing, nella variante più semplice queste sono macchine con un nastro infinito su cui inizialmente c'è scritto l'input.
		Per questi linguaggi se la stringa appartiene al linguaggio il riconoscitore termina sempre con sì, mentre se la stringa non appartiene al linguaggio il riconoscitore può anche non terminale ($\bot$)
\end{itemize}

\begin{teorema}
	I linguaggi di tipo 1, 2 e 3 sono anche detti decidibili o ricorsivi.
	(Un insieme ricorsivo è un insieme per cui posso avere una macchina che può rispondere sì o no alla domanda se un insieme appartenga)
\end{teorema}
\begin{proof}
Sia $G$ una grammatica di tipo 1 e $w$ una stringa di terminali di lunghezza $n = |w|$, voglio sapere se $w$ appartiene a $G$.
Siccome la grammatica di tipo 1 è monotonica (le regole forme sentenziali non possono decrescere), queste non possono mai superare $n$ durante la derivazione di $w$.
Chiamiamo 
$$T_i = { \gamma \in (V \cup \Sigma)^{\leq n} \mid S \overset{\leq i}{\Rightarrow} \gamma }$$
Costruiamo gli insiemi $T_i$ per $i = 0, 1, \dots$
\begin{align*}
	T_0 &= { S } \\
	    &\vdots \\
	T_i &= T_{i - 1} \cup { \gamma \in (V \cup \Sigma)^{\leq n} \mid \exists \beta \in T_{i - 1} . \beta \Rightarrow \gamma } 
\end{align*}
Allora 
$$T_0 \subseteq T_1 \subseteq \dots \subseteq T_{i - 1} \subseteq T_{i} \subseteq \dots \subseteq (V \cup \Sigma)^{\leq n}$$
Dato che $(V \cup \Sigma)^{\leq n}$ è un insieme finito, quindi esiste un certo $i$ tale che $T_i = T_{i - 1}$.
A questo punto ho trovato tutte le forme sentenziali di lunghezza $n$, e per vedere se $w$ appartiene al linguaggio basta controllare che $w \in T_i$.


Quello che posso fare è considerare l'insieme 
$$U_i = { \gamma \in (V \cup \Sigma)^* \mid S \overset{\leq i}{\Rightarrow} \gamma }$$
Quindi ancora
\begin{align*}
	U_0 &= { S } \\
	    &\vdots \\
	U_i &= U_{i - 1} \cup { \gamma \in (V \cup \Sigma)^* \mid \exists \beta \in U_{i - 1} . \beta \Rightarrow \gamma } 
\end{align*}
$$U_0 \subseteq U_1 \subseteq \dots \subseteq U_{i - 1} \subseteq U_{i} \subseteq \dots \subseteq (V \cup \Sigma)^*$$
Quindi che nei linguaggi di tipo 0 perdo la monotonicità delle derivazioni, non posso più trovare una $i$ tale che $U_i = U_{i - 1}$.
Però per ogni $U_i$ posso controllare se $w \in U_i$, infatti se la grammatica genera $w$, prima o poi questa la troverò, se non la genera non la troverò mai.
\end{proof}

Il motivo per cui si dicono ricorsivamente enumerabili è perché si può costruire un programma che elenchi tutti gli elementi del linguaggio.

%% fine lezione 2, inizio lezione 3
La gerarchia di Chomksy vale per alfabeti di almeno due lettere.

\section{Parola vuota ed $\epsilon$-produzioni}
Supponendo di avere una grammatica $G$ di tipo 1, supponiamo di voler aggiungere la parola vuota al linguaggio generato.
Se si aggiunge banalmente la regola per la parola vuota
$$ S \prd \epsilon $$
non ci sono garanzie che noi non abbiamo aggiunto anche altre stringhe al linguaggio, ad esempio nel caso
$$ \alpha \der \dots S \dots $$
inoltre perdiamo la proprietà della monotonicità delle forme sentenziali.

Quindi bisogna essere leggermente più delicati, dato $L = L(G)$, voglio costruire $G^\prime$ tale che $L^\prime = L(G^\prime) = L(G) \cup \{ \epsilon \}$.
Per gare ciò definisco $G^\prime = \grammar{V \cup \{S^\prime\}}{\Sigma}{P \cup \{ S^\prime \prd \epsilon \mid S\}}{S^\prime}$.

Dal simbolo iniziale posso utilizzare $S \prd \epsilon$ purché $S$ non appaia su lato destro di nessuna produzione.
Questo ovviamente vale anche per grammatiche di tipo 2 e 3.

Data una grammatica di tipo 2 che utilizza $\epsilon$-produzioni 
$$ A \prd \epsilon $$
è possibile trovare una grammatica di tipo 2 equivalente che genera lo stesso linguaggio, meno la parola vuota, che non utilizza $\epsilon$-produzioni.

Anche nelle gramamtiche di tipo 3 possiamo ammettere $\epsilon$-produzioni
$$ A \prd \epsilon $$

\section{Automa a stati finiti}
Un automa è un dispositivo che ha
\begin{itemize}
	\item un nastro diviso in celle che contiene l'input, ogni cella contiene un simbolo dell'alfabeto
		Questo non può essere modificato.
	\item una testina che passa il nastro da sinistra a destra, per questo vengono chiamati anche automi $one-way$.
		Quando questa finisce il nastro deve poter rispondere se la parola appartiene o no al linguaggio.
		La testina contiene una macchina che ha un insieme finito di stati.
\end{itemize}
Un automa è quindi una quintupla $\mathscr{A} = \langle Q, \Sigma, \delta, q_0, F \rangle$, dove
\begin{itemize}
	\item $Q$ è l'insieme degli stati
	\item $\Sigma$ è l'alfabeto finito di input
	\item $\delta$ è il programma dell'automa, o funzione di transizione
	\item $q_0 \in Q$ è lo stato iniziale
	\item $F \subseteq Q$ è l'insieme degli stati finali
\end{itemize}
Ad ogni passo l'automa legge un simbolo, ed in base allo stato attuale e il simbolo in input sceglie il prossimo stato con $\delta$
$$ \delta : Q \times \Sigma \rightarrow Q $$
Definiamo 
$$ \delta^* : Q \times \Sigma^* \rightarrow Q $$
per induzione sulla lunghezza delle stringhe in input:
\begin{itemize}
	\item $\forall q \in Q \mid \delta^*(q, \epsilon) = q $
	\item $\forall q \in Q, x \in \Sigma^*, a \in \Sigma \mid \delta^*(q, x a) = \delta(\delta^*(q, x), a)$
\end{itemize}
Visto che $\delta^*$ è effettivamente una estensione di $\delta$, chiameremo $\delta^*$ $\delta$.

Ora possiamo definire il linguaggio riconosciuto dall'automa $\mathscr{A}$ come
$$ L(\mathscr{A}) = \{ w \in \Sigma^* \mid \delta(q_0, w) \in F \} $$

\begin{tcolorbox}
	Ad esempio $\mathscr{A} = \langle Q = \{ q_0, q_1 \}, \Sigma = \{ a, b \}, \delta, q_0, F = \{ q_1 \} \rangle$, con $\delta$ definita come
	\begin{center}
	%	\begin{tblr}{c| c c }
	%		\delta & a & b \\
	%		\hline
	%		q_0    & q_0 & q_1 \\
	%		q_1    & q_1 & q_0 \\
	%	\end{tblr}
	\end{center}
	Per $aabb$ abbiamo
	$$ q_0 \overset{a}{\rightarrow} q_0 \overset{a}{\rightarrow} q_0 \overset{b}{\rightarrow} q_1 \overset{b}{\rightarrow} q_0 $$
	quindi la stringa non è accettata perché $q_0 \not \in F$.
	Questo è linguaggoi di tutte le stringhe con un numero dispari di $b$.
\end{tcolorbox}
Invece che rappresentare $\delta$ come una tabella, di solito è comodo rappresentarla come un diagramma di transizione:
\begin{itemize}
	\item Lo stato iniziale è rappresentato da una freccia entrante
	\item gli stati finali da un doppio cerchio.
\end{itemize}
Quindi una derivazione non è altro che un cammino in questo grafo, e la parola è accettata se si finisce in uno stato finale.

\begin{tcolorbox}
	Dato $\Sigma = \{ a, b \}$, e il linguaggio 
	$$ \mathscr{L} = \{ x \in \Sigma^* \mid P(x) \}$$
	con $P$ definita come la proprietà per cui tra ogni coppia di $b$ successive in $x$ c'è un numero di $a$ pari.
	\begin{center}
		\begin{tikzpicture}
			\node[state, initial, accepting] 	(q_0) {$q_0$};
			\node[state, accepting] 		(q_1) [right=of q_0] {$q_1$};
			\node[state, accepting]			(q_2) [right=of q_1] {$q_2$};
			\node[state]				(q_3) [right=of q_2] {$q_3$};

			\path[->] (q_0)	edge[loop above]	node[above]	{a}	()
					edge			node[above]	{b}	(q_1)
				  (q_1)	edge[loop above]	node[above]	{b}	()
					edge			node[above]	{a}	(q_2)
				  (q_2)	edge			node[above]	{}	(q_1)
				  	edge			node[above]	{b}	(q_3)
				  (q_3)	edge[loop above]	node[above]	{a, b}	();
		\end{tikzpicture}
	\end{center}
	% 
	%  init(final(q_0)) --b--> final(q_1) <--a--> final(q_2) --b--> trap(q_3)
	%         \_a_/             \_b_/                                \_a,b_/
	Visto che 
	$$ \delta : Q \times \Sigma \rightarrow Q $$
	nello stato $q_2$ bisogna aggiungere una freccia ad uno stato da cui non si può uscire, infatti se siamo in quello stato vuol dire che abbiamo trovato un numero dispari di $a$ e una $b$, quindi la parola non è valida.
	Questo tipo di stati è detto stato trappola, e di solito vengono lasciati impliciti.
\end{tcolorbox}

\begin{tcolorbox}
	Dato $\Sigma = \{ a, b \}$, e il linguaggio 
	$$ \mathscr{L} = \{ x \in \Sigma^* \mid \text{Il terzo simbolo di $x$ è una $a$}\}$$
	% init(q_0) --a,b--> q_1 --a,b--> q_2 --a--> final(q_3)
	%                                             \_a,b_/
	\begin{center}
		\begin{tikzpicture}
			\node[state, initial] 	(q_0) {$q_0$};
			\node[state]		(q_1) [right=of q_0] {$q_1$};
			\node[state]		(q_2) [right=of q_1] {$q_2$};
			\node[state, accepting]	(q_3) [right=of q_2] {$q_3$};

			\path[->] (q_0)	edge			node[above]	{a, b}	(q_1)
				  (q_1)	edge			node[above]	{a,b}	(q_2)
				  (q_2)	edge			node[above]	{a}	(q_3)
				  (q_3)	edge[loop above]	node[above]	{a, b}	();
		\end{tikzpicture}
	\end{center}
\end{tcolorbox}
\begin{tcolorbox}
	Dato $\Sigma = \{ a, b \}$, e il linguaggio 
	$$ \mathscr{L} = \{ x \in \Sigma^* \mid \text{ Il terzultimo simbolo di $x$ è una $a$} \} $$
	Teniamo uno stato per ogni tripla di $a, b$, quindi $2^3 = 8$ stati
	% graph automa {
	% aaa -b-> aab
	% aaa -a-> aaa
	% aab -a-> aba
	% aab -b-> abb
	% aba -a-> baa
	% aba -b-> bab
	% bab -a-> aba
	% bab -b-> abb
	% abb -a-> bba
	% abb -b-> bbb
	% baa -a-> aaa
	% baa -b-> aab
	% bbb -b-> bbb
	% bbb -a-> bba
	% bba -a-> baa
	% bba -b-> bab
	% fin(aaa)
	% fin(aab)
	% fin(aba)
	% fin(abb)
	% init(bbb)
	% }
\end{tcolorbox}

Una operazione che può interessare per le stringhe è costruire il linguaggio che riconosce le stringhe roversciate di uno.
Dato un linguaggio $\mathscr{L}$, il linguaggio che riconosce le sue stringhe inverse è detto il reversal di $\mathscr{L}$.
Nel caso dei due linguaggi precedenti se prendiamo l'automa del primo e lo invertiamo ottieniamo un automa valido (non deterministico) per il secondo.

\subsection{Automi non deterministici}
Definiamo un automa non deterministico come la quintupla $\mathscr{A} = \langle Q, \Sigma, \delta, q_0, F \rangle$, ma ora $\delta$ è definita come
$$ \delta : Q \times \Sigma \rightarrow 2^Q $$
quindi $\delta$ non ritorna più un singolo insieme ma un insieme di possibili stati.

Una stringa viene accettata se esiste almeno un cammino che mi porta in uno stato finale.
Estensiamo ancora $\delta$ alle stringhe 
$$ \delta^* : Q \times \Sigma \rightarrow 2^Q $$
è definita come
\begin{itemize}
	\item $\forall q \in Q \mid \delta^*(q, \epsilon) = \{ q \} $
	\item $\forall q \in Q, x \in \Sigma^*, a \in \Sigma \mid \delta^*(q, xa) = \bigcup_{p \in \delta^*(q, x)} \delta(p, a) $
\end{itemize}

Come prima chiameremo $\delta^*$ semplicemente $\delta$.

Ora il linguaggio accettato dall'automa $\mathscr{A}$ non deterministico è $L(\mathscr{A}) = \{ w \in \Sigma^* \mid \delta(q_0, w) \cap F \neq \varnothing \}$.

\begin{tcolorbox}
	Dato l'automa non deterministico
	\begin{center}
		\begin{tikzpicture}
			\node[state, initial] 	(r_0) {$r_0$};
			\node[state] 	      	(r_1) [right=of r_0] {$r_1$};
			\node[state] 	      	(r_2) [right=of r_1] {$r_2$};
			\node[state, accepting]	(r_3) [right=of r_2] {$r_3$};

			\path[->] (r_0)	edge	[loop above]	node[above]	{a, b}	()
					edge			node[above]	{a}	(r_1)
				  (r_1)	edge			node[above]	{a, b}	(r_2)
				  (r_2)	edge			node[above]	{a, b}	(r_3);
		\end{tikzpicture}
	\end{center}
	con la stringha $ababb$ mostriamo tutte le possibili strade che si possono prendere
	\begin{center}
		\begin{tikzpicture}
			\node {$r_0$}
				child { node {$r_0$}
					child {	node {$r_0$}
						child {	
							node {$r_0$} 
							child {
								node {$r_0$}
								child {
									node {$\cancel{r_0}$}
									edge from parent node[left] {b}
								}
								edge from parent node[left] {b}
							}
							edge from parent node[left] {a}
						}
						child { 
							node {$r_1$} 
							child {
								node {$r_2$}
								child {
									node {$r_3$}
									edge from parent node[right] {b}
								}
								edge from parent node[right] {b}
							}
							edge from parent node[right] {a}
						}
						edge from parent node[left] {b}
					}
					edge from parent node[left] {a}
				}
				child {	
					node {$r_1$}
					child {
						node {$r_2$}
						child {
							node {$\cancel{r_3}$}
							edge from parent node[right] {a}
						}
						edge from parent node[right] {b}
					}
					edge from parent node[right] {a}
				};
		\end{tikzpicture}
	\end{center}
	è necessario che esista almeno una strada dell'albero che risponda sì per accettare.
	Questa struttura è chiamato albero di computazione, e un cammino descrive una computazione.

	Bisogna supporre che l'automa riesca a sceglie la strada esatta.
	Alternativamente si può pensare che l'automa possa visitare tutte le strade in parallelo, quindi possiamo trasformare l'albero in
	\begin{center}
		\begin{tikzpicture}
			\node[state, initial] 	(r0) {$\{ r_0 \}$};
			\node[state] 	      	(r0r1)	[right=of r0] {$\{ r_0, r_1 \}$};
			\node[state] 	      	(r0r2)	[right=of r0r1] {$\{ r_0, r_2 \}$};
			\node[state] 	      	(r0r1r3)[below right=of r0r2] {$\{ r_0, r_1, r_3 \}$};
			\node[state, accepting]	(r0r3) 	[right=of r0r2] {$\{ r_0, r_3 \}$};

			\path[->] (r0)		edge	node[above]	{a}	(r0r1)
				  (r0r1) 	edge	node[above]	{b}	(r0r2)
				  (r0r2)	edge	node[above]	{a}	(r0r1r3)
				  		edge 	node[above]	{b}	(r0r3)
				  (r0r1r3)	edge	node[above]	{a}	(r0r2);
		\end{tikzpicture}
	\end{center}
	Questo 
\end{tcolorbox}
Ogni autma non deterministico (NFA) con $n$ stati può sempre essere trasformato in un automa deterministico con al più $2^n$ stati.
Nel caso degli automi a pila invece il modello non deterministico è più potente.
Qui invece tra DFA e NFA non cambia la potenza computazionale, ma la semplicità descrittiva.
\end{document}

\documentclass[12pt]{report}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[italian]{babel}
\usepackage{bytefield}
\usepackage{cancel}
\usepackage{caption}
% \usepackage{embedall}\embedfile{\jobname.tex}
\usepackage{float}
\usepackage[bookmarks]{hyperref}
\usepackage{listings}
\usepackage[scr=rsfs]{mathalpha}
\usepackage{siunitx}
\usepackage{subcaption}
\usepackage{tabularray}
\usepackage[most]{tcolorbox}
\usepackage{pgfplots}
\usepgfplotslibrary{fillbetween}
\usepackage{tikz}\usetikzlibrary{automata, chains, scopes, decorations.text, patterns, patterns.meta, decorations.pathmorphing, positioning, decorations.pathreplacing, calligraphy, math, fit, shapes.geometric, pgfplots.fillbetween}
\usetikzlibrary{external}
\usepackage{todonotes}
\usepackage{xcolor}

\newtheorem{teorema}{Teorema}
\newtheorem{corollario}{Corollario}
\newtheorem{proposizione}{Proposizione}
\newtheorem{proprietà}{Proprietà}
\newtheorem{lemma}{Lemma}
\newtheorem{fatto}{Fatto}
\theoremstyle{definition}
\newtheorem{definizione}{Definizione}
\theoremstyle{regard}
\newtheorem{nota}{Nota}

\renewcommand\qedsymbol{$\blacksquare$}

% \usepackage{teolang}

\definecolor{codegray}{gray}{0.95}

\lstdefinestyle{mystyle}{
  numberstyle=\tiny,
  basicstyle=\footnotesize,
  breaklines=true,
  numbers=left,
  numbersep=5pt,
}
\lstset{style=mystyle}

\overfullrule=0.2cm

\tikzexternalize 
\tcbset{shield externalize}
\begin{document}
\tableofcontents
\newpage

\chapter{Intro}
Gli automi a pila sono automi che oltre ad avere un controllo a stati finiti hanno una memoria arbitrariamente grande, ma organizzata a pila; cioè una memoria a cui si può accedere solo all'elemento più in cima.
Questo modello è one-way sul nastro di input, e dimostreremo che la versione two-way è più potente. % ref

Durante il corso analizzeremo principalmente il modello nondeterministico, infatti un altro risultato che dimostriamo % ref
è che il modello deterministico è -- a differenza degli FSA -- meno potente di quello nondeterministico.

Un automa a pila è una tupla
$$ M = \langle Q, \Sigma, \Gamma, \delta, q_0, Z_0, F \rangle $$
\noindent dove
\begin{itemize}
	\item $\Gamma$ è l'alfabeto della pila o alfabeto di lavoro
	\item $\delta$ è la funzione di transizione
	\item $q_0 \in Q$ è lo stato iniziale dell'automa
	\item $Z_0 \in \Gamma$ è lo stato iniziale della pila
	\item $F$ è un insieme di stati finali
\end{itemize}
La funzione di transizione dipende da tre cose: dallo stato corrente, dal simbolo dell'input corrente e dal simbolo in cima alla pila
$$ \delta : Q \times (\Sigma \cup \{\varepsilon\}) \times \Gamma \rightarrow \text{PF}(Q \times \Gamma^*) $$
La funzione di transizione contemporaneamente cambia lo stato dell'automa e rimpiazza il simbolo in cima alla pila con una stringa di stati della pila\footnote{$\text{PF}(-)$ sta per le parti finite, infatti se utilizzassimo $2^{Q \times \Gamma^*}$ potremmo avere programmi infiniti, visto che $\Gamma^*$ è un insieme infinito.} \footnote{Scriviamo $\Sigma \cup \{ \varepsilon \}$ perché sono contemplate mosse in base allo stato dell'automa che modificano la pila senza leggere un simbolo in input.} \footnote{Per convenzione la stringa di stati viene messa sulla pila da destra a sinistra, quindi il simbolo più a sinistra sarà in cima alla pila.}.
% fig 12.1
\begin{figure}[H]
	\centering
	\begin{tikzpicture}[ SQUIGGLY/.style={->
			  		     , decorate
			                     , decoration={snake,amplitude=.4mm,segment length=2mm,post length=1mm}},
			   ]
 		\begin{scope}[local bounding box=wordScope, start chain=word, node distance=0pt]
    			\node [draw, minimum width=40pt, minimum height=20pt, on chain=word] {$\dots$};
			\node [draw, minimum height=20pt, on chain=word] {$a$};
    			\node [draw, minimum width=40pt, minimum height=20pt, on chain=word] {$\dots$};
 		\end{scope}

		\node[draw, minimum width=20pt, minimum height=20pt] (state) [below=of word-2]	{$q$};

		\begin{scope}[local bounding box=stackScope, start chain=stack going below, node distance=0pt]
			\node [draw, minimum width=20pt, on chain=stack] [right=of state, xshift=1cm] {$A$};
    			\node [draw, minimum width=20pt, minimum height=40pt, on chain=stack] {$\vdots$};
 		\end{scope}

		\node (a) [above=of stack-1, yshift=-1cm] {\tiny Pila};
		\node (b) [above=of word-2, yshift=-1cm] {\tiny Parola};
		\node (c) [below=of state, yshift=1cm] {\tiny Stato};

		\draw[SQUIGGLY] (state.north) to (word-2.south);
		\draw[SQUIGGLY] (state.east) to (stack-1.west);
	\end{tikzpicture}
	\caption{Rappresentazione delle varie parti di un PDA}
\end{figure}
% Visto che sono ammesse $\varepsilon$-mosse il modello di sopra potrebbe non esaurire tutte le possibilità.

\begin{tcolorbox}[breakable]
\label{ex:1}
Supponiamo di essere nello stato 
\begin{center}
	\begin{tikzpicture}[ SQUIGGLY/.style={->
			  		     , decorate
			                     , decoration={snake,amplitude=.4mm,segment length=2mm,post length=1mm}},
			   ]
 		\begin{scope}[local bounding box=wordScope, start chain=word, node distance=0pt]
    			\node [draw, minimum width=40pt, minimum height=20pt, on chain=word] {$\dots$};
    			\node [draw, minimum height=20pt, on chain=word] {$a$};
    			\node [draw, minimum width=40pt, minimum height=20pt, on chain=word] {$\dots$};
 		\end{scope}

		\node[draw, minimum width=20pt, minimum height=20pt] (state) [below=of word-2]	{$q$};

		\begin{scope}[local bounding box=stackScope, start chain=stack going below, node distance=0pt]
			\node [draw, minimum width=20pt, on chain=stack] [right=of state, xshift=1cm] {$A$};
    			\node [draw, minimum width=20pt, minimum height=40pt, on chain=stack] {$\vdots$};
 		\end{scope}

		\draw[SQUIGGLY] (state.north) to (word-2.south);
		\draw[SQUIGGLY] (state.east) to (stack-1.west);
	\end{tikzpicture}
\end{center}
e che la funzione $\delta$ sia così definita
$$\delta(q, a, A) = \{(q_1, \varepsilon), (q_2, BCC)\} $$
L'applicazione delle due alternative porterebbe l'automa nei seguenti stati
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.4\textwidth}
		\centering
		\begin{tikzpicture}[ SQUIGGLY/.style={->
			, decorate
			, decoration={snake,amplitude=.4mm,segment length=2mm,post length=1mm}},
			]
			\begin{scope}[local bounding box=wordScope, start chain=word, node distance=0pt]
				\node [draw, minimum width=40pt, minimum height=20pt, on chain=word] {$\dots$};
				\node [draw, minimum height=20pt, on chain=word] {$a$};
				\node [draw, minimum height=20pt, on chain=word] {$?$};
				\node [draw, minimum width=40pt, minimum height=20pt, on chain=word] {$\dots$};
			\end{scope}

			\node[draw, minimum width=20pt, minimum height=20pt] (state) [below=of word-3]	{$q_1$};

			\begin{scope}[local bounding box=stackScope, start chain=stack going below, node distance=0pt]
				\node [draw, minimum width=20pt, minimum height=40pt, on chain=stack] [right=of state, xshift=1cm] {$\vdots$};
			\end{scope}

			\draw[SQUIGGLY] (state.north) to (word-3.south);
			\draw[SQUIGGLY] (state.east) to (stack-1.west);
		\end{tikzpicture}
		\caption{Lo stato per $(q_1, \varepsilon)$}
	\end{subfigure}
	\begin{subfigure}{0.4\textwidth}
		\centering
		\begin{tikzpicture}[ SQUIGGLY/.style={->
			, decorate
			, decoration={snake,amplitude=.4mm,segment length=2mm,post length=1mm}},
			]
			\begin{scope}[local bounding box=wordScope, start chain=word, node distance=0pt]
				\node [draw, minimum width=40pt, minimum height=20pt, on chain=word] {$\dots$};
				\node [draw, minimum height=20pt, on chain=word] {$a$};
				\node [draw, minimum height=20pt, on chain=word] {$?$};
				\node [draw, minimum width=40pt, minimum height=20pt, on chain=word] {$\dots$};
			\end{scope}

			\node[draw, minimum width=20pt, minimum height=20pt] (state) [below=of word-3]	{$q_2$};

			\begin{scope}[local bounding box=stackScope, start chain=stack going below, node distance=0pt]
				\node [draw, minimum width=20pt, on chain=stack] [right=of state, xshift=1cm] {$B$};
				\node [draw, minimum width=20pt, on chain=stack] {$C$};
				\node [draw, minimum width=20pt, on chain=stack] {$C$};
				\node [draw, minimum width=20pt, minimum height=40pt, on chain=stack] {$\vdots$};
			\end{scope}

			\draw[SQUIGGLY] (state.north) to (word-3.south);
			\draw[SQUIGGLY] (state.east) to (stack-1.west);
		\end{tikzpicture}
		\caption{Lo stato per $(q_2, BCC)$}
	\end{subfigure}
\end{figure}
Inoltre potremmo anche avere $\varepsilon$-mosse, ad esempio $ \delta(q, \varepsilon, A) = \{(r, B)\} $, porterebbe l'automa nello stato
\begin{center}
	\begin{tikzpicture}[ SQUIGGLY/.style={->
			  		     , decorate
			                     , decoration={snake,amplitude=.4mm,segment length=2mm,post length=1mm}},
			   ]
 		\begin{scope}[local bounding box=wordScope, start chain=word, node distance=0pt]
    			\node [draw, minimum width=40pt, minimum height=20pt, on chain=word] {$\dots$};
    			\node [draw, minimum height=20pt, on chain=word] {$a$};
    			\node [draw, minimum width=40pt, minimum height=20pt, on chain=word] {$\dots$};
 		\end{scope}

		\node[draw, minimum width=20pt, minimum height=20pt] (state) [below=of word-2]	{$r$};

		\begin{scope}[local bounding box=stackScope, start chain=stack going below, node distance=0pt]
			\node [draw, minimum width=20pt, on chain=stack] [right=of state, xshift=1cm] {$B$};
    			\node [draw, minimum width=20pt, minimum height=40pt, on chain=stack] {$\vdots$};
 		\end{scope}

		\draw[SQUIGGLY] (state.north) to (word-2.south);
		\draw[SQUIGGLY] (state.east) to (stack-1.west);
	\end{tikzpicture}
\end{center}
\end{tcolorbox}

\section{Definizioni}\label{sect:def}
Ci riferiremo agli automi a pila come PDA (Push Down Automaton) e assumeremo che siano sempre nondeterministici, a meno che diversamente specificato.

Chiameremo lo stato complessivo dell'automa a pila la sua \textbf{configurazione}, questa verrà rappresentata compattamente come la tripla dello stato corrente, la porzione di input ancora da leggere, e il contenuto della pila.
Quindi 
% fig 12.3
\begin{center}
	\begin{tikzpicture}[ SQUIGGLY/.style={->
			  		     , decorate
			                     , decoration={snake,amplitude=.4mm,segment length=2mm,post length=1mm}},
			   ]
 		\begin{scope}[local bounding box=wordScope, start chain=word, node distance=0pt]
    			\node [draw, minimum width=40pt, minimum height=20pt, on chain=word] {$x$};
			\node [draw, minimum height=20pt, on chain=word] {$a$};
    			\node [draw, minimum width=40pt, minimum height=20pt, on chain=word] {$y$};
 		\end{scope}

		\node[draw, minimum width=20pt, minimum height=20pt] (state) [below=of word-2]	{$q$};

		\begin{scope}[local bounding box=stackScope, start chain=stack going below, node distance=0pt]
			\node [draw, minimum width=20pt, on chain=stack] [right=of state, xshift=1cm] {$A$};
    			\node [draw, minimum width=20pt, minimum height=40pt, on chain=stack] {$\alpha$};
 		\end{scope}

		\draw[SQUIGGLY] (state.north) to (word-2.south);
		\draw[SQUIGGLY] (state.east) to (stack-1.west);
	\end{tikzpicture}
\end{center}
è rappresentato dalla configurazione
$$ (q, ay, A\alpha) $$
con $q \in Q, a \in \Sigma \cup \{\varepsilon\}, y \in \Sigma^*, A \in \Gamma, \alpha \in \Gamma^*$.

Una mossa, scritto $q \vdash p$, indica che da una configurazione $q$ posso passare ad un'altra $p$.
Ad esempio nell'Esempio \ref{ex:1} abbiamo che
\begin{align*}
	(q, ay, A\alpha) &\vdash (q_1, y, \alpha) \\
	(q, ay, A\alpha) &\vdash (q_2, y, BCC\alpha) \\
	(q, ay, A\alpha) &\vdash (r, ay, B\alpha)
\end{align*}
Più rigorosamente, sia $(q, ay, Z\alpha)$ la configurazione corrente, con $Z \in \Gamma$ e $M$ l'automa a pila, diciamo che
$$ (q, ay, Z\alpha) \underset{M}{\vdash} (p, y, \beta\alpha) $$
sse $(p, \beta) \in \delta(q, a, Z)$ dove $q, p \in Q$, $y \in \Sigma^*$, $a \in \Sigma \cup \{\varepsilon\}$, $Z \in \Gamma$ e $\alpha, \beta \in \Gamma^*$.
Se l'automa è ovvio dal contesto possiamo ometterlo da $\underset{M}{\vdash}$ e scrivere solo $\vdash$.

Da una configurazione $C'$ arrivo ad una configurazione $C''$ in un certo numero di mosse -- scritto 
$$ C' \underset{M}{\overset{*}{\vdash}} C'' $$
sse esistono $C_0, \dots, C_k$ con $C_0 = C'$ e $C_k = C''$ e $\forall i \in 1, \dots, k \; C_{i - 1} \underset{M}{\vdash} C_i$.

La configurazione iniziale di un automa su input $w \in \Sigma^*$ è 
$$ (q_0, w, Z_0) $$

Per accettare possiamo dare alcune diverse definizioni di configurazione accettante:
\begin{itemize}
	\item una volta finito l'input mi trovo in uno stato $q \in F$ e la pila può essere una stringa qualunque, questa è detta \textit{accettazione per stati finali}\footnote{Siccome sono accettate le $\varepsilon$ mosse può esserci il caso in arriviamo alla fine dell'input con uno stato non finale, e si può fare una $\varepsilon$-mossa ed arrivare ad uno stato finale.}
			, ed indichiamo il linguaggio accettato per stati finali dall'automa a pila $M$ come
		$$ L(M) = \{ w \in \Sigma^* \mid (q_0, w, Z_0) \overset{*}{\vdash} (q, \varepsilon, \gamma), q \in F, \gamma \in \Gamma^* \} $$
	\item è ragionevole pensare che tutto quello che viene messo sulla pila debba anche essere tolto, questa è detta \textit{accettazione per pila vuota} per cui si deve arrivare alla fine dell'input ed aver svuotato l'intera pila, ignorando lo stato.
		Il linguaggio accettato per pila vuota dall'automa $M$ lo indichiamo come
		$$ N(M) = \{ w \in \Sigma^* \mid (q_0, w, Z_0) \overset{*}{\vdash} (q, \varepsilon, \varepsilon), q \in Q \} $$
		In questo caso ovviamente si può omettere $F$ dalla definizione dell'automa.
	\item si può pensare di richiedere entrambe le precedenti, come vedremo più avanti queste tre nozioni sono equivalenti nel caso nondeterministico (Sezione \ref{sect:eq-nondet}).
\end{itemize}
\begin{nota} % sistemo
	Questa cosa la vedremo meglio, ma visto che la pila è la struttura fondamentale per la ricorsione, i linguaggi CF sono i linguaggi regolari a cui è stata aggiunta la ricorsione.
\end{nota}

\begin{tcolorbox}
	Definiamo il linguaggio
	$$ \mathcal{L} = \{ a^n b^n \mid n \geq 1 \} $$
	possiamo usare la pila per contare il numero di $a$.
	\begin{align*}
		\delta(q_0, a, Z_0) &= \{(q_0, A)\} \\
		\delta(q_0, a, A)   &= \{(q_0, AA) \} \\
		\delta(q_0, b, A)   &= \{ (q_1, \varepsilon) \} \\
		\delta(q_1, b, A)   &= \{ (q_1, \varepsilon) \} 
	\end{align*}
	E vale che data questa $\delta$
	$$ \mathcal{L} = N(M) $$
	Questo caso particolare di automa a pila in cui utilizziamo in simbolo solo (cioè $A$, oltre a $Z_0$) è detto \textit{automa a contatore}.

	Definiamo alternativamente
	\begin{align*}
		\delta(q_0, a, Z_0) &= \{(q_0, AZ_0)\} \\
		\delta(q_0, a, A)   &= \{(q_0, AA)\} \\
		\delta(q_0, b, A)   &= \{(q_1, \varepsilon)\} \\
		\delta(q_1, b, A)   &= \{(q_1, \varepsilon)\} \\
		\delta(q_1, \varepsilon, Z_0) &= \{(q_F, \varepsilon)\}
	\end{align*}
	con $F = \{q_F\}$, e vale che con questa $\delta$
	$$ \mathcal{L} = L(M) $$

	% sistemo wording
	Vediamo ora il caso di sopra, ma in cui
	$$ \mathcal{L} = \{ a^n b^n \mid n \geq 0 \} $$
	possiamo usare la pila per contare il numero di $a$.
	\begin{align*}
		\delta(q_0, \varepsilon, Z_0) &= \{(q_0, \varepsilon)\} \\
		\delta(q_0, a, Z_0) &= \{(q_0, A)\} \\
		\delta(q_0, a, A)   &= \{(q_0, AA) \} \\
		\delta(q_0, b, A)   &= \{ (q_1, \varepsilon) \} \\
		\delta(q_1, b, A)   &= \{ (q_1, \varepsilon) \} 
	\end{align*}
	E vale che data questa $\delta$ in cui si può direttamente accettare dallo stato $q_0$
	$$ \mathcal{L} = N(M) $$
	L'introduzione della prima regola è problematica, perché con input non vuoto permette di svuotare la pila da $Z_0$, bloccando la continuazione dell'automa, quindi abbiamo introdotto il nondeterminismo tra le due regole $\delta(q_0, \varepsilon, Z_0)$ e $\delta(q_0, a, Z_0)$.

	Definiamo similmente a sopra
	\begin{align*}
		\delta(q_0, \varepsilon, Z_0) &= \{(q_F, \varepsilon)\} \\
		\delta(q_0, a, Z_0) &= \{(q_0, AZ_0)\} \\
		\delta(q_0, a, A)   &= \{(q_0, AA)\} \\
		\delta(q_0, b, A)   &= \{(q_1, \varepsilon)\} \\
		\delta(q_1, b, A)   &= \{(q_1, \varepsilon)\} \\
		\delta(q_1, \varepsilon, Z_0) &= \{(q_F, \varepsilon)\}
	\end{align*}
	con $F = \{q_F\}$, e vale che con questa $\delta$
	$$ \mathcal{L} = L(M) $$
	sempre introducendo non determinismo.
	
	Questa versione, a differenza di quello di sopra per pila vuota, può anche essere fatta senza non determinismo infatti definiamo $q_I$ come nuovo stato iniziale che è anche finale, se la stringa è vuota possono direttamente accettare, mentre 
	$$ \delta(q_I, a, Z_0) = \{(q_0, AZ_0)\} $$
	ci riconduce all'automa di sopra.
\end{tcolorbox}

Definiamo ora l'automa a pila deterministico.
Questo in ogni configurazione permette una singola scelta:
\begin{itemize}
	\item sono vietate configurazioni che ammettono una mossa e una $\varepsilon$-mossa, quindi $\forall q \in Q, z \in \Gamma$ se $\delta(q, \varepsilon, z) \neq \varnothing$ allora $\forall a \in \Sigma \; \delta(q, a, Z) = \varnothing$
	\item per ogni tripletta $q, a, Z$ è ammessa al massimo una mossa, quindi 
		$$\forall q \in Q, z \in \Gamma, a \in \Sigma \cup \{\varepsilon\} \mid |\delta(q, a, Z)|\leq 1$$
\end{itemize}
% A questo punto abbiamo definito quattro modelli: deterministico e nondeterministico che possono accettare per pila vuota o per stato finale.
% Vedremo che il caso nondeterminismo in questo caso è più potente del caso deterministico, e che nel modello nondeterministico automi che possono accettare per pila vuota o per stato finale sono equivalenti.

\section{Equivalenza tra le due nozioni di accettazione nel modello nondeterministico}\label{sect:eq-nondet}
Dimostriamo ora che le due nozioni di PDA che abbiamo visto nella Sezione \ref{sect:def} sono equivalenti.
\begin{proof}[Da stati finali a pila vuota]
Dato un automa $M = (Q, \Sigma, \Gamma, \delta, q_0, Z_0, F)$ e supponiamo che $L = L(M)$ sia il linguaggio accettato per stati finali.
Definiamo l'automa 
$$M' = (Q \cup \{q_0', q_e\}, \Sigma, \Gamma \cup \{X\}, \delta', q_0', X, \varnothing)$$
con $q_0', q_e \not \in Q$ e $X \not \in \Gamma$, vogliamo che $L= N(M')$.

Ad alto livello quando $M$ arriva in uno stato finale, $M'$ si sposta nello stato $q_e$ in cui inizia a svuotare la pila.
Infatti la $e$ di $q_e$ sta per ``empty''.

Definiamo ora $\delta'$:
\begin{enumerate}
	\item prima di tutto 
		$$ \delta'(q_0', \varepsilon, X) = \{(q_0, Z_0X)\} $$
		questo serve solo ad infilare $X$ in fondo alla pila.
		La $X$ è necessaria per evitare che se l'automa iniziale $M$ svuota la pila si accetti la stringa.
	\item per ogni altra cosa $M'$ si può comportare come $M$:
		$$ \forall q \in Q, a \in \Sigma \cup \{\varepsilon\}, z \in \Gamma \mid \delta(q, a, Z) \subseteq \delta'(q, a, Z) $$
	\item ogni qualvolta $M$ entra in uno stato finale $M'$ può -- enfasi su può -- iniziare a svuotare l'intera pila:
		$$ \forall q \in F, z \in \Gamma \cup \{X\} \mid (q_e, \varepsilon) \in \delta'(q, \varepsilon, Z) $$
	\item una volta entrato nello stato di svuotamento, continua a svuotare:
		$$ \forall z \in \Gamma \cup \{X\} \mid \delta'(q_e, \varepsilon, Z) = \{(q_e, \varepsilon)\}$$ 
\end{enumerate}

Questo necessariamente introduce nondeterminismo, infatti l'automa $M$ potrebbe entrare in uno stato finale prima di essere arrivato alla fine della stringa.
Ed anche se l'automa di partenza è deterministico il punto $3$ potrebbe in ogni caso introdurre nondeterminismo.

Supponiamo di avere un automa deterministico che accetta la stringa $w$ a pila vuota, allora ogni stringa che ha $w$ come prefisso non può essere accettata, perché il prefisso $w$ svuoterebbe la pila e un automa con pila vuota non può andare a avanti.
Quindi il nondeterminismo è in un certo senso necessario per automi a pila che accettano con pila vuota.
\end{proof}
\begin{proof}[Da pila vuota a stati finali]
Dato un automa $M = (Q, \Sigma, \Gamma,\delta, q_0, Z_0, \varnothing)$ che accetta per pila vuota il linguaggio $L = N(M)$, vogliamo creare un automa che accetti per stati finali.
Sia questo 
$$M' = (Q \cup \{q_0', q_F\}, \Sigma, \Gamma \cup \{X\}, \delta', q_0', X, F = \{q_F\})$$
con $q_0', q_F \not \in Q, X \not \in \Gamma$.

Definiamo ora $\delta'$:
\begin{itemize}
	\item come prima inizialmente infiliamo $X$ in fondo alla pila:
		$$ \delta'(q_0', \varepsilon, X) = \{(q_0, Z_0X)\} $$
		$X$ serve a riconoscere quando la pila è vuota.
	\item a questo punto copiamo tutte le mosse di $M$, per cui
		$$ \forall q \in Q, a \in \Sigma \cup \{\varepsilon\}, Z \in \Gamma \mid \delta'(q, a, Z) = \delta(q, a, Z) $$
	\item nel momento in cui $M$ svuota la prima, $M'$ si trova $X$ sulla pila, a questo punto può entrare in uno stato finale
		$$ \forall q \in Q \mid \delta'(q, \varepsilon, X) = \{(q_F, \varepsilon)\}$$
\end{itemize}
Supponendo che $M$ sia deterministico, $M'$ rimane deterministico -- la trasformazione preserva il determinismo.
\end{proof}

% lezione 13
\chapter{Grammatiche di tipo 2}
Una grammatica è formata da quattro elementi:
$$ G = \langle V, \Sigma, P, S \rangle $$
e nello specifico, in quelle di tipo 2 le produzioni hanno la forma
$$ A \rightarrow \alpha \hspace{1cm} A \in V, \alpha \in (V \cup \Sigma)^* $$

Una rappresentazione utile per le derivazioni di linguaggi CF sono gli alberi, ad esempio data $w \in L(G)$, allora $S \overset{*}{\Rightarrow} w$.
Questa derivazione io la possono rappresentare come un albero di derivazione, o albero di parsing, o ancora parse tree.
Questo è un albero 
\begin{itemize}
	\item con radice etichettata con il simbolo iniziale della grammatica
	\item le foglie da sinistra a destra sono $w$
	\item i nodi possono essere di tre tipi:
		\begin{itemize}
			\item variabili, per i nodi interni
			\item terminali, per le foglie
			\item $\varepsilon$ la parola vuota, in casi speciali per le foglie
		\end{itemize}
\end{itemize}
Dato un nodo
\begin{center}
	\begin{tikzpicture}
		\node {$A$}
			child { node {$X_1$} }
			child { node {$X_2$} }
			child { node {$\dots$} }	% non disegno il nodo
			child { node {$X_k$} };
	\end{tikzpicture}
\end{center}
rappresenta l'applicazione della regola di produzione
$$ A \rightarrow X_1 X_2 \dots X_k \in P \hspace{1cm} A \in V, \forall i \in 1, \dots, k \mid X_i \in V \cup \Sigma $$
All'ultimo livello possiamo avere nodi
\begin{center}
	\begin{tikzpicture}
		\node {$A$}
		child { node {$\varepsilon$} };
	\end{tikzpicture}
\end{center}
solo se $A \rightarrow \varepsilon \in P$.

Abbiamo detto che gli automi a pila riconoscono linguaggi con ricorsione, dove questa nell'automa si esprime nella memoria a pila, nelle grammatiche si esprime nella struttura ad albero.
 
% \begin{tcolorbox}[breakable] 	% extra \else error with externalized tikzpicture
Definiamo la grammatica per le parentesi correttamente bilanciate
\begin{align*}
	S &\rightarrow \varepsilon \\
	S &\rightarrow ( S ) \\
	S &\rightarrow S S
\end{align*}
prendiamo ora la stringa $w = (())()()$ e scriviamone la derivazione
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.3\textwidth}
		\centering
		\begin{tikzpicture}[scale=0.45, every node/.style={transform shape}]
			\node {$S$}
				[sibling distance=4.5cm]
				child { node {$S$} 
					[sibling distance=3cm]
					child { node {$S$} 
						[sibling distance=1cm]
						child { node {$($} }
						child { node {$S$} 
							[sibling distance=1cm]
							child { node {$($} }
							child { node {$S$} 
								child { node {$\varepsilon$} }
							}
							child { node {$)$} }
						}
						child { node {$)$} }
					}
					child { node {$S$}
						[sibling distance=1cm]
						child { node {$($} }
						child { node {$S$} 
							child { node {$\varepsilon$} }
						}
						child { node {$)$} }
					}
				}
				child { node {$S$} 
					[sibling distance=1cm]
					child { node {$($} }
					child { node {$S$} 
						child { node {$\varepsilon$} }
					}
					child { node {$)$} }
				};
		\end{tikzpicture}
		\begin{align*}
			S &\Rightarrow S S  \\
			&\Rightarrow S S S  \\
			&\Rightarrow ( S ) S S  \\
			&\Rightarrow ( S ) ( S ) S  \\
			&\Rightarrow ( S ) ( S ) ( S )  \\
			&\Rightarrow ( ( S ) ) ( S ) ( S )  \\
			&\Rightarrow ( ( S ) ) ( S ) ( )  \\
			&\Rightarrow ( ( S ) ) ( ) ( )  \\
			&\Rightarrow ( ( ) ) ( ) ( )  \\
		\end{align*}
	\end{subfigure}
	\begin{subfigure}{0.3\textwidth}
		\centering
		\begin{tikzpicture}[scale=0.45, every node/.style={transform shape}]
 			\node {$S$}
			[sibling distance=4.5cm]
 			child { node {$S$} 
				[sibling distance=1cm]
 				child { node {$($} }
 				child { node {$S$} 
					[sibling distance=1cm]
 					child { node {$($} }
 					child { node {$S$} 
 						child { node {$\varepsilon$} }
 					}
 					child { node {$)$} }
 				}
 				child { node {$)$} }
 			}
 			child { node {$S$} 
				[sibling distance=3cm]
 				child { node {$S$} 
					[sibling distance=1cm]
 					child { node {$($} }
 					child { node {$S$} 
 						child { node {$\varepsilon$} }
 					}
 					child { node {$)$} }
 				}
 				child { node {$S$}
					[sibling distance=1cm]
 					child { node {$($} }
 					child { node {$S$} 
 						child { node {$\varepsilon$} }
 					}
 					child { node {$)$} }
 				}
 			};
 		\end{tikzpicture}
		\begin{align*}
			S &\Rightarrow S S  \\
			  &\Rightarrow ( S ) S  \\
			  &\Rightarrow ( ( S ) ) S  \\
			  &\Rightarrow ( ( ) ) S  \\
			  &\Rightarrow ( ( ) ) S S  \\
			  &\Rightarrow ( ( ) ) ( S ) S  \\
			  &\Rightarrow ( ( ) ) ( ) S  \\
			  &\Rightarrow ( ( ) ) ( ) ( S )  \\
			  &\Rightarrow ( ( ) ) ( ) ( )  \\
		\end{align*}
	\end{subfigure}
	\begin{subfigure}{0.3\textwidth}
		\centering
		\begin{tikzpicture}[scale=0.45, every node/.style={transform shape}]
			\node {$S$}
				[sibling distance=4.5cm]
				child { node {$S$} 
					[sibling distance=3cm]
					child { node {$S$} 
						[sibling distance=1cm]
						child { node {$($} }
						child { node {$S$} 
							[sibling distance=1cm]
							child { node {$($} }
							child { node {$S$} 
								child { node {$\varepsilon$} }
							}
							child { node {$)$} }
						}
						child { node {$)$} }
					}
					child { node {$S$}
						[sibling distance=1cm]
						child { node {$($} }
						child { node {$S$} 
							child { node {$\varepsilon$} }
						}
						child { node {$)$} }
					}
				}
				child { node {$S$} 
					[sibling distance=1cm]
					child { node {$($} }
					child { node {$S$} 
						child { node {$\varepsilon$} }
					}
					child { node {$)$} }
				};
		\end{tikzpicture}
	 	\begin{align*}
	 		S &\Rightarrow S S \\
	 		  &\Rightarrow S S S \\
	 		  &\Rightarrow ( S ) S S \\
	 		  &\Rightarrow ( ( S ) ) S S \\
	 		  &\Rightarrow ( ( ) ) S S \\
	 		  &\Rightarrow ( ( ) ) ( S ) S \\
	 		  &\Rightarrow ( ( ) ) ( ) S \\
	 		  &\Rightarrow ( ( ) ) ( ) ( S ) \\
	 		  &\Rightarrow ( ( ) ) ( ) ( ) \\
	 	\end{align*}
	\end{subfigure}
	\caption{Tre derivazioni diverse per la stringa $(())()()$ e gli alberi corrispondenti}
\end{figure}
Possiamo vedere che una stessa stringa ammette diverse derivazioni, ma non tutte queste portano allo stesso albero.
Infatti la prima e la terza derivazione utilizzano le stesse sostituzioni, solo in ordine diverso, e quindi generano alberi uguali; mentre nel secondo albero applichiamo derivazioni diverse.
Nella prima e nella terza derivazione abbiamo una struttura
\begin{center}
	\begin{tikzpicture}
		\node {$S$}
		child { node {$S$} 
			child { node {$\Delta$} }
			child { node {$\Delta$} }
		}
		child { node {$\Delta$} };
	\end{tikzpicture}
\end{center}
mentre la seconda ha una struttura
\begin{center}
	\begin{tikzpicture}
		\node {$S$}
		child { node {$\Delta$} }
		child { node {$S$} 
			child { node {$\Delta$} }
			child { node {$\Delta$} }
		};
	\end{tikzpicture}
\end{center}
% \end{tcolorbox}

Per evitare derivazioni multiple si utilizza un criterio detto di \textit{derivazione leftmost}: una derivazione è lefmost se ogni volta che si fa una sostituzione sostituisco sempre la variabile più a sinistra della forma sentenziale.
\begin{proposizione}
	Esiste una corrispondenza uno a uno tra derivazioni leftmost e alberi di derivazione.
\end{proposizione}
La seconda e la terza derivazioni dell'esempio di sopra sono due derivazioni leftmost diverse.

\begin{definizione}
Diciamo che una grammatica è \textit{ambigua} se c'è una stringa che ammette almeno due alberi di derivazione -- o derivazioni leftmost -- diversi.
\end{definizione}

Nell'esempio di sopra si può vedere anche che ogni sottoalbero è una sequenza bilanciate di parentesi.

\begin{tcolorbox} % [breakable] 	% stesso problema di sopra
Se nella grammatica di sopra vorremmo anche le quadre, senza precedenze, questa è facilmente
\begin{align*}
 	S &\rightarrow \varepsilon \\
 	S &\rightarrow ( S ) \\
 	S &\rightarrow [ S ] \\
 	S &\rightarrow S S
\end{align*}
Ma se si chiede che le quadre non possano stare all'interno delle tonde, diventa necessario suddividere le variabili in due livelli
\begin{align*}
 	S &\rightarrow T \\
 	S &\rightarrow [ S ] \\
 	S &\rightarrow S S \\
 	T &\rightarrow \varepsilon \\
 	T &\rightarrow ( T ) \\
 	T &\rightarrow T T \\
\end{align*}
e vediamo un albero di derivazione di esempio
\begin{center}
	\begin{tikzpicture}
		\node {$S$}
		[sibling distance=1cm, level distance=1cm]
		child { node {$[$} }
		child { node {$S$} 
			[sibling distance=3cm]
			child { node {$S$} 
				[sibling distance=1cm]
				child { node {$T$} 
					child { node {$($} }
					child { node {$T$} 
						child { node {$\varepsilon$} }
					}
					child { node {$)$} }
				}
			}
			child { node {$S$} 
				[sibling distance=1cm]
				child { node {$[$} }
				child { node {$S$} 
					child { node {$T$}
						child { node {$\varepsilon$} }
					}
				}
				child { node {$]$} }
			}
		}
		child { node {$]$} };
	\end{tikzpicture}
\end{center}
\end{tcolorbox}


\section{Equivalenza tra grammatiche di tipo 2 ad automi a pila}
Mostriamo ora l'equivalenza tra le grammatiche di tipo 2 e gli automi a pila.
\begin{proof}[Da una grammatica che genera un linguaggio generiamo un automa che riconosce lo stesso]
Data una grammatica
$$ G = \langle V, \Sigma, P, S \rangle $$
di tipo 2, vogliamo costruire
$$ M = \langle Q, \Sigma, \Gamma, \delta, q, Z_0, \varnothing \rangle $$
che accetta per pila vuota, con
\begin{itemize}
 	\item $Q$ formato da un solo stato $\{q\}$
 	\item $\Gamma = \Sigma \cup V$
 	\item $Z_0 = S$
\end{itemize}
e $\delta$ definito come
\begin{itemize}
 	\item se $A \rightarrow \alpha \in P$ allora $(q, \alpha) \in \delta(q, \varepsilon, A)$
 	\item $\forall \sigma \in \Sigma$, $\delta(q, \sigma, \sigma) = \{ (q, \varepsilon) \}$, cioè si consuma il simbolo in cima alla pila
\end{itemize}
 
Si può dimostrare che il linguaggio generato dalla grammatica $L(G)$ è uguale al linguaggio accettato dall'automa per pila vuota $N(M)$.
\end{proof}

\begin{tcolorbox}[breakable]
 	Prendiamo
 	$$ G = \langle \{S, T, U\}, \{a, b\}, P, S \rangle $$
 	con $P$ definito
 	\begin{align*}
 		S &\rightarrow TU  \\
 		T &\rightarrow a T b \mid \varepsilon \\
 		U &\rightarrow b U a \mid \varepsilon \\
 	\end{align*}
 	questo genera
 	$$ L = \{ a^n b^{n + m} a^m \mid n \geq 0, m \geq 0 \} $$
 
 	Scriviamo le transizioni dell'automa corrispondente
 	$$ M = \langle \{q\}, \{a, b\}, \{S, T, U, a, b\}, \delta, q, S, \varnothing \rangle $$
 	con $\delta$ definito come
 	\begin{align*}
 		\delta(q, \varepsilon, S) &= \{(q, TU)\} \\
 		\delta(q, \varepsilon, T) &= \{(q, a T b), (q, \varepsilon) \} \\
 		\delta(q, \varepsilon, U) &= \{(q, b U a), (q, \varepsilon) \} \\
 		\delta(q, a, a) &= \{(q, \varepsilon)\} \\
 		\delta(q, b, b) &= \{(q, \varepsilon)\} \\
 	\end{align*}
 	\newpage
 	Prendendo per esempio $w = abbbaa$, vediamo come viene accettata nondeterministicamente
 	\begin{align*}
 		(q, abbbaa, S) &\vdash (q, abbbaa, TU) \\
 		               &\vdash (q, abbbaa, TU) \\
 		               &\vdash (q, abbbaa, aTbU) \\
 		               &\vdash (q, bbbaa, TbU) \\
 		               &\vdash (q, bbbaa, bU) \\
 		               &\vdash (q, bbaa, U) \\
 		               &\vdash (q, bbaa, bUa) \\
 		               &\vdash (q, baa, Ua) \\
		               &\vdash (q, baa, bUaa) \\
 		               &\vdash (q, aa, Uaa) \\
 		               &\vdash (q, aa, aa) \\
 		               &\vdash (q, a, a) \\
 		               &\vdash (q, \varepsilon, \varepsilon) \\
 	\end{align*}
 	Leggere la i terminali consumati fino a un certo punto e il contentuto della pila in quel punto restituisce la forma sentenziale durante la derivazione.
 	Questo corrisponde a
 	\begin{align*}
 		S &\Rightarrow T U \\
 		  &\Rightarrow a T b U \\
 		  &\Rightarrow a b U \\
 		  &\Rightarrow a b b U a \\
 		  &\Rightarrow a b b b U a a \\
 		  &\Rightarrow a b b b a a \\
 	\end{align*}
\end{tcolorbox}
L'automa a pila tenta di simulare il processo di derivazione leftmost della stringa.

Mostriamo ora il lato opposto dell'equivalenza, per fare questo però 
% iniziamo a introdurla
Per la dimostrazione useremo una variazione degli automi a pila che non ne cambia la potenza computazionale.
In questa forma normale
\begin{itemize}
	\item all'inizio la pila contiene un simbolo speciale $Z_0$ che viene mai rimosso e non viene mai aggiunto
 		% lez 13.1
		\begin{center}
			\begin{tikzpicture}[ SQUIGGLY/.style={->
				, decorate
				, decoration={snake,amplitude=.4mm,segment length=2mm,post length=1mm}},
				]
				\begin{scope}[local bounding box=wordScope, start chain=word, node distance=0pt]
					\node [draw, minimum width=25pt, minimum height=25pt, on chain=word] {$\sigma$};
					\node [draw, minimum width=65pt, minimum height=25pt, on chain=word] {$\dots$};
				\end{scope}

				\node[draw, minimum width=25pt, minimum height=25pt] (state) [below=of word-1] {$q_0$};
				\node[draw, minimum width=25pt, minimum height=25pt] (stack) [right=of state] {$Z_0$};

				\draw[SQUIGGLY] (state.north) to (word-1.south);
				\draw[SQUIGGLY] (state.east) to (stack.west);
			\end{tikzpicture}
		\end{center}
 	\item alla fine l'input è stato letto completamente, la pila contiene solo $Z_0$ e lo stato è finale.
 		% lez 13.2
		\begin{center}
			\begin{tikzpicture}[ SQUIGGLY/.style={->
				, decorate
				, decoration={snake,amplitude=.4mm,segment length=2mm,post length=1mm}},
				]
				\begin{scope}[local bounding box=wordScope, start chain=word, node distance=0pt]
					\node [draw, minimum width=65pt, minimum height=25pt, on chain=word] {$\dots$};
					\node [minimum width=25pt, minimum height=25pt, on chain=word] {};
				\end{scope}

				\node[draw, minimum width=25pt, minimum height=25pt] (state) [below=of word-2] {$q_F$};
				\node[draw, minimum width=25pt, minimum height=25pt] (stack) [right=of state] {$Z_0$};

				\draw[SQUIGGLY] (state.north) to (word-2.south);
				\draw[SQUIGGLY] (state.east) to (stack.west);
			\end{tikzpicture}
		\end{center}
 	\item le mosse sulla pila possono essere solo
 		\begin{itemize}
 			\item push di un simbolo
 			\item pop di un simbolo
		 	\item pila invariata
 		\end{itemize}
 		quindi il pop non è più implicito
 	\item se una mossa legge un simbolo da input, allora non modifica la pila. 
 		Cioè le mosse che manipolano la pila sono seperate da quelle che manipolano l'input.
\end{itemize}
In questa forma
$$ \delta : Q \times (\Sigma \cup \{\varepsilon\}) \times \Gamma \rightarrow 2^{Q \times \{-, \text{pop}, a \in \Gamma \mid \text{push}(A)\}} $$
ed abbiamo che le mosse possono avere le seguenti forme
\begin{itemize}
 	\item mosse di lettura: $ (p, -) \in \delta(q, a, A) \hspace{1cm} a \in \Sigma \cup \{\varepsilon\} $
 	\item pop: $(p, \text{pop}) \in \delta(q, \varepsilon , A) $
 	\item push: $(p, \text{push}(B)) \in \delta(q, \varepsilon , A) $
 	\item mosse che lasciano la pila invariata: $(p, -) \in \delta(q, \varepsilon , A) $
\end{itemize}
 
\begin{tcolorbox}
 	Ad esempio se avessimo una sequenza di parentesi $([()]())$, la pila contiene inizialmente $Z_0$
	\begin{center}
		\begin{tikzpicture}[ SQUIGGLY/.style={->
			, decorate
			, decoration={snake,amplitude=.4mm,segment length=2mm,post length=1mm}},
			]
			\begin{scope}[local bounding box=col1, start chain=col1 going above, node distance=0pt]
				\node [minimum width=25pt, minimum height=25pt, on chain=col1] {$Z_0$};
			\end{scope}
			\begin{scope}[local bounding box=col2, start chain=col2 going above, node distance=0pt]
				\node [minimum width=25pt, minimum height=25pt, on chain=col2] [right=of col1-1]{$Z_0$};
				\node [minimum width=25pt, minimum height=25pt, on chain=col2] {$($};
			\end{scope}
			\begin{scope}[local bounding box=col3, start chain=col3 going above, node distance=0pt]
				\node [minimum width=25pt, minimum height=25pt, on chain=col3] [right=of col2-1]{$Z_0$};
				\node [minimum width=25pt, minimum height=25pt, on chain=col3] {$($};
				\node [minimum width=25pt, minimum height=25pt, on chain=col3] {$[$};
			\end{scope}
			\begin{scope}[local bounding box=col4, start chain=col4 going above, node distance=0pt]
				\node [minimum width=25pt, minimum height=25pt, on chain=col4] [right=of col3-1]{$Z_0$};
				\node [minimum width=25pt, minimum height=25pt, on chain=col4] {$($};
				\node [minimum width=25pt, minimum height=25pt, on chain=col4] {$[$};
				\node [minimum width=25pt, minimum height=25pt, on chain=col4] {$($};
			\end{scope}
			\begin{scope}[local bounding box=col5, start chain=col5 going above, node distance=0pt]
				\node [minimum width=25pt, minimum height=25pt, on chain=col5] [right=of col4-1]{$Z_0$};
				\node [minimum width=25pt, minimum height=25pt, on chain=col5] {$($};
				\node [minimum width=25pt, minimum height=25pt, on chain=col5] {$[$};
			\end{scope}
			\begin{scope}[local bounding box=col6, start chain=col6 going above, node distance=0pt]
				\node [minimum width=25pt, minimum height=25pt, on chain=col6] [right=of col5-1]{$Z_0$};
				\node [minimum width=25pt, minimum height=25pt, on chain=col6] {$($};
			\end{scope}
			\begin{scope}[local bounding box=col7, start chain=col7 going above, node distance=0pt]
				\node [minimum width=25pt, minimum height=25pt, on chain=col7] [right=of col6-1]{$Z_0$};
				\node [minimum width=25pt, minimum height=25pt, on chain=col7] {$($};
				\node [minimum width=25pt, minimum height=25pt, on chain=col7] {$($};
			\end{scope}
			\begin{scope}[local bounding box=col8, start chain=col8 going above, node distance=0pt]
				\node [minimum width=25pt, minimum height=25pt, on chain=col8] [right=of col7-1]{$Z_0$};
				\node [minimum width=25pt, minimum height=25pt, on chain=col8] {$($};
			\end{scope}
			\begin{scope}[local bounding box=col9, start chain=col9 going above, node distance=0pt]
				\node [minimum width=25pt, minimum height=25pt, on chain=col9] [right=of col8-1]{$Z_0$};
			\end{scope}

			% \node [below=of col2-1] {$($};
			% \node [below=of col3-1] {$[$};
			% \node [below=of col4-1] {$($};
			% \node [below=of col5-1] {$)$};
			% \node [below=of col6-1] {$]$};
			% \node [below=of col7-1] {$($};
			% \node [below=of col8-1] {$)$};
			% \node [below=of col9-1] {$)$};

			\node [left=of col1-1, xshift=1cm, yshift=2.5cm] {\rotatebox[origin=c]{90}{\tiny Pila}};
			\node [below=of col9-1, yshift=1cm] {\tiny Input};

			\draw[->] ([xshift=-0.45cm] col1-1.south) -- ([xshift=8cm] col1-1.south);
			\draw[->] ([yshift=-0.45cm] col1-1.west) -- ([yshift=3cm] col1-1.west);
			\draw[dashed] ([xshift=-2.75cm] col4-2.south) -- ([xshift=4.5cm] col4-2.south) node[xshift=0.5cm] {\tiny $([()]())$};
			\draw[dashed] ([xshift=-2.75cm] col4-3.south) -- ([xshift=4.5cm] col4-3.south) node[xshift=0.5cm] {\tiny $[()], ()$};
			\draw[dashed] ([xshift=-2.75cm] col4-4.south) -- ([xshift=4.5cm] col4-4.south) node[xshift=0.5cm] {\tiny $()$};

		\end{tikzpicture}
	\end{center}
 	questo disegno mostra la natura ricorsiva degli automi.
	Infatti visto che la pila di questo automa non può mai scendere sotto il suo livello iniziale, tutte le evoluzioni definite dalle linee tratteggiate definiscono parole valide del linguaggio.
\end{tcolorbox}
 
\begin{nota}
	Gli automi che abbiamo visto fino ad ora possono essere simulati da questa versione normalizzata, scomponendo una mossa una pop ed una serie di push utilizzando degli stati ausiliari.
\end{nota}

\begin{proof}[Da un automa a pila costruiamo una grammatica di tipo 2]
	% todo sistemo bene
\end{proof}

% lezione 14
Ripetiamo la versione di automa a pila semplificato vista a lezione scorsa, in questo per riuscire ad accettare dobbiamo arrivare in uno stato finale con solo $Z_0$ lo stato finale sulla pila.

Dobbiamo trovare un modo di trasformare un automa a pila come definito nella lezione scorsa, in una grammatica.
Questa grammatica ha nonterminali della forma $[qAp]$ con $q, p \in Q$ e $A \in V$, e rappresenta:
\begin{itemize}
	\item $q$ è lo stato in cui si inizia
	\item $p$ è lo stato in cui si finisce 
	\item e $A$ è il simbolo in cima alla pila all'inizio e alla fine della computazione.
\end{itemize}
% fig 14.1
\begin{figure}[H]
	\centering
	\begin{tikzpicture}
		\draw[->] (0, 0) -- (0, 4) node[left, yshift=-0.2cm] {\rotatebox{90}{\tiny pila}};
		\draw[->] (0, 0) -- (5, 0) node[below, xshift=-0.2cm] {\tiny input};

		\node[label=left:{\tiny $q, A$}] at (1, 1) [circle,fill,inner sep=1.5pt] (a) {};
		\node[label=right:{\tiny $p, A$}] at (4, 1) [circle,fill,inner sep=1.5pt] (b) {};

		\tikzmath {
			real \x, \rand, \precx, \precy;
			\precx = 1;
			\precy = 1;
			for \x in {1.2,1.4,...,3.8} {
				\rand = 1 + (random(0, 100) / 66);
				{ \draw[-] (\precx, \precy) -- (\x, \rand); };
				\precx = \x;
				\precy = \rand;
			};
			{ \draw[-] (\precx, \precy) -- (4, 1); };
		}
		\draw[dashed] (1, 1) -- (1, 0);
		\draw[dashed] (4, 1) -- (4, 0);
		\draw[dashed] (1, 1) -- (4, 1);
		\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] (1, 0) to node[below, yshift=-0.2cm] {\tiny $w$} (4, 0);
	\end{tikzpicture}
	\caption{La computazione rappresentata dal simbolo $[qAp]$}
\end{figure}
Infatti negli automi come li abbiamo definiti, vale la proprietà per cui ??? % Z_0

Definiamo ora le regole di produzione della grammatica induttivamente come le stringhe riconosciute dalla computazione $[qAp]$:
\begin{itemize}
	\item base: abbiamo due casi
		\begin{itemize}
			\item caso $0$: il caso più semplice è $[qAq]$, qui l'unica parola riconosciuta è $\varepsilon$, quindi è necessaria la regola
				$$ [qAq] \rightarrow \varepsilon $$
				Quindi creo tutte le produzioni della forma
				$$ \forall q \in Q, A \in \Gamma \mid [qAq] \rightarrow \varepsilon $$	% domanda pighi su computazione che inizia e finisce nello stato q
			\item caso $0'$: il secondo caso più semplice è quello in qui si è nello stato $q$, si consuma un carattere o nessuno, e questo ci porta nello stato $p$; cioè $(p, -) \in \delta(q, a, A)$ con $a \in \Sigma \cup \{\varepsilon\}$.
				Questo si traduce nella produzione
				$$ [qAp] \rightarrow a, \hspace{1cm} a \in \Sigma \cup \{\varepsilon\} $$
				Quindi creo tutte le produzioni della forma
				$$ \forall q, p \in Q, A \in \Gamma, a \in \Sigma \cup \{\varepsilon\} \mid [qAp] \rightarrow a $$
		\end{itemize}
	\item passo: si distinguono due casi
		\begin{figure}[H]
			\centering
			\begin{subfigure}{0.45\textwidth}
				\centering
				\begin{tikzpicture}
					\draw[->] (0, 0) -- (0, 4) node[left, yshift=-0.2cm] {\rotatebox{90}{\tiny pila}};
					\draw[->] (0, 0) -- (5, 0) node[below, xshift=-0.2cm] {\tiny input};

					\node[label=left:{\tiny $q, A$}] at (1, 1) [circle,fill,inner sep=1.5pt] (a) {};
					\node[label=right:{\tiny $p, A$}] at (4, 1) [circle,fill,inner sep=1.5pt] (b) {};
					\node[label=below right:{\tiny $r, A$}] at (3, 1) [circle,fill,inner sep=1.5pt] (c) {};
			
					\tikzmath {
						real \x, \rand, \precx, \precy;
						\precx = 1;
						\precy = 1;
						for \x in {1.2,1.4,...,2.8} {
							\rand = 1.2 + (random(0, 100) / 80);
							{ \draw[-] (\precx, \precy) -- (\x, \rand); };
							\precx = \x;
							\precy = \rand;
						};
						{ \draw[-] (\precx, \precy) -- (3, 1); };
						\precx = 3;
						\precy = 1;
						for \x in {3.2,3.4,...,3.8} {
							\rand = 1.2 + (random(0, 100) / 80);
							{ \draw[-] (\precx, \precy) -- (\x, \rand); };
							\precx = \x;
							\precy = \rand;
						};
						{ \draw[-] (\precx, \precy) -- (4, 1); };
					}
					\draw[dashed] (1, 1) -- (1, 0);
					\draw[dashed] (3, 1) -- (3, 0);
					\draw[dashed] (4, 1) -- (4, 0);
					\draw[dashed] (1, 1) -- (4, 1);
					\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] (1, 0) to node[below, yshift=-0.1cm] {\tiny $w'$} (3, 0);
					\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] (3, 0) to node[below, yshift=-0.1cm] {\tiny $w''$} (4, 0);
					\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] (1, -0.5) to node[below, yshift=-0.1cm] {\tiny $w$} (4, -0.5);
				\end{tikzpicture}
				\caption{Caso 2}
			\end{subfigure}
			\begin{subfigure}{0.45\textwidth}
				\centering
				\begin{tikzpicture}
					\draw[->] (0, 0) -- (0, 4) node[left, yshift=-0.2cm] {\rotatebox{90}{\tiny pila}};
					\draw[->] (0, 0) -- (5, 0) node[below, xshift=-0.2cm] {\tiny input};

					\node[label=left:{\tiny $q, A$}] at (1, 1) [circle,fill,inner sep=1.5pt] (a) {};
					\node[label=left:{\tiny $q', B$}] at (1.1, 1.4) [circle,fill,inner sep=1.5pt] (b) {};
					\node[label=right:{\tiny $p', B$}] at (3.9, 1.4) [circle,fill,inner sep=1.5pt] (c) {};
					\node[label=right:{\tiny $p, A$}] at (4, 1) [circle,fill,inner sep=1.5pt] (d) {};

					\draw[-] (a) -- (b);
					\draw[-] (c) -- (d);
			
					\tikzmath {
						real \x, \rand, \precx, \precy;
						\precx = 1.1;
						\precy = 1.4;
						for \x in {1.2,1.4,...,3.6} {
							\rand = 1.5 + (random(0, 100) / 80);
							{ \draw[-] (\precx, \precy) -- (\x, \rand); };
							\precx = \x;
							\precy = \rand;
						};
						{ \draw[-] (\precx, \precy) -- (3.9, 1.4); };
					}
					\draw[dashed] (1, 1) -- (1, 0);
					\draw[dashed] (4, 1) -- (4, 0);
					\draw[dashed] (1, 1) -- (4, 1);
					\draw[dashed] (1.1, 1.4) -- (3.9, 1.4);
					\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] (1, 0) to node[below, yshift=-0.2cm] {\tiny $w$} (4, 0);
				\end{tikzpicture}
				\caption{Caso 1}
			\end{subfigure}
		\end{figure}
		% fig 14.2
		\begin{itemize}
			\item caso 1: nei passi intermedi (tranne l'ultimo) la pila è sempre strettamente più alta di quando si è iniziato, questo si traduce in
				$$ [qAp] \rightarrow [q'Bp'] $$
				con $(q', \text{push}(B)) \in \delta(q, \varepsilon, A)$ e $(p, \text{pop}) \in \delta(p', \varepsilon, B)$.
				Quindi 
				\begin{multline*}
				\forall q, q', p, p' \in Q, A, B \in \Gamma \\ \mid
					(q', \text{push}(B)) \in \delta(q, \varepsilon, A) \wedge (p, \text{pop}) \in \delta(p', \varepsilon, B) \\
					\Rightarrow [qAp] \rightarrow [q'Bp'] 
				\end{multline*}
			\item caso 2: la computazione $[qAp]$ svuota la pila fino alla $A$ inizia e poi continua, allora possiamo scomporre la computazione in due parti, quindi
				$$ \forall q, p, r \in Q, A \in \Gamma \mid [qAp] \rightarrow [qAr][rAp] $$
		\end{itemize}
\end{itemize}
Si può dimostrare che
\begin{lemma}
	$\forall q, p \in Q, A \in \Gamma, w \in \Sigma^* \mid [qAp] \overset{*}{\Rightarrow} w$ sse 
	% fig 14.3
	l'automa $M$ in una configurazione con $A$ in cima alla pila, stato $q$, dopo aver letto $w$ raggiunge una configurazione in cui il contentuto della pila è lo stesso dell'inizio, lo stato è $p$ e nei passi intermedi la pila non scende mai sotto il livello iniziale.
\end{lemma}
Quindi durante una computazione quello che c'è sotto al simbolo in cima alla pina all'inizio della computazione non è rilevante.

Per finire di costruire la grammatica manca di definire l'assioma.
Prima di tutto si può notare che visto che l'automa parte nello stato $q_0$ con $Z_0$ e basta sulla pila, una stringa $w$ può essere generata solo dalle triple 
$$[q_0Z_0q_F] \overset{*}{\Rightarrow} w$$
con $q_0$ iniziale e $q_F$ finale.
Quindi definiamo l'insieme dei nonterminali della grammatica $V$ come l'insieme di tutte le triple definite induttivamente sopra unito ad un nuovo nonterminale $S$ tale che
$$ \forall q_F \in F \mid S \rightarrow [q_0 Z_0 q_F] \in P $$
e questo $S$ così definito è il simbolo iniziale.

\section{Forme normali per le grammatiche di tipo 2}
Si può vedere che tutte le produzioni generate dalla traduzione da automa a pila a grammatica sono di pochi tipi: variabile a terminale, variabile a variabile e variabile a coppia di variabili.
Da questo fatto e dal fatto che i linguaggi riconosciuti dagli automi a pila sono esattamente quelli generati dalle grammatiche di tipo 2, ci rendiamo conto che possiamo restringere di molto il tipo di forma che il lato destro di una produzione di una grammatica CF può assumere.
Nel caso di sopra appunto da variabile a terminale, da variabile a variabile e da variabile a coppia di variabili.

Vediamo ora due forme normali.
Ogni grammatica può essere trasformata in una di queste forme normali a patto di sacrificare la parola vuota.

\subsection{Forma normale di Greibach}
In una grammatica in FNG (Forma Normale di Greibach) tutte le produzioi sono della forma
$$ A \rightarrow a B_1 \dots B_k, \hspace{1cm} a \in \Sigma, A, B_1, \dots, B_k \in V, k \geq 0 $$

Supponiamo di avere la gramamtica
\begin{align*}
	A &\rightarrow a B B \\
	A &\rightarrow b \\
	B &\rightarrow b B \\
	B &\rightarrow b
\end{align*}
e di aver fatto la trasformazione in automa a pila.
In questa forma normale la pila avrà in cima sempre un terminale e quindi si può avere un simbolo di lookahead e scegliere più precisamente la prossima produzione da utilizzare, anche se non si toglie il nondeterminismo (v. $B \rightarrow b B$ e $B \rightarrow b$).
Un altro vantaggio di avere sempre un terminale in cima alla pila è che in questo tipo di automa si possono eliminare le $\varepsilon$-mosse.

\subsection{Forma normale di Chomsky}
Nella FNC (Forma Normale di Chomsky) ci sono solo due tipi di regole
\begin{align*}
	A & \rightarrow B C & A, B, C \in V \\
	A & \rightarrow a & A \in V, a \in \Sigma \\
\end{align*}
Questa genera alberi di derivazione binari, salvo sulle foglie; ed è comoda per studiare alcune proprietà combinatorie.

\subsubsection{Trasformazione in FNC}
Data una grammatica genererica $G$ eseguiamo i seguenti passi (l'ordine è importante) per trasformarla in FNC:
\begin{enumerate}
	\item eliminazione delle $\varepsilon$-produzioni: diciamo che una variabile $A$ è \textit{cancellabile} sse $A \overset{*}{\Rightarrow} \varepsilon$.
		Induttivamente $A$ è cancellabile se
		\begin{itemize}
			\item banalmente $A \rightarrow \varepsilon$
			\item o se $A \rightarrow X_1 X_2 \dots X_k$ e $X_1, X_2, \dots, X_k$ sono tutti cancellabili.
		\end{itemize}
		Questo può essere definito come una chiusura dove
		$$ C_0 = \{ A \mid A \rightarrow \varepsilon \} $$
		e 
		$$ C_i = C_{i - 1} \cup \{ A \mid \exists A \rightarrow X_1 X_2 \dots X_k \; \text{con} \; \forall i \in 1, \dots, k \mid X_i \in C_{i - 1} \} $$
		Visto che
		$$ C_0 \subseteq C_1 \subseteq \dots \subseteq V $$
		e $V$ è finito, allora esiste un $i$ tale che $C_i = C_{i - 1}$.

		Ora sia $C$ l'insisme delle variabili cancellabili, costruiamo una grammatica $G' = \langle V, \Sigma, P', S \rangle$ con $P'$ costituito da tutte le produzioni di $P$ eccetto le $\varepsilon$ produzioni e per ogni produzione $A \rightarrow X_1 X_2 \dots X_k$ con $X_1, X_2, \dots, X_k \in V \cup \Sigma$ aggiungo a $P'$ le produzioni $A \rightarrow X_{i_1} X_{i_2} \dots X_{i_j}$ tali che $1 \leq i_1 < i_2 < \dots < i_j \leq k$ e per $\forall X_l \not \in X_{i_1}, \dots, X_{i_j} \mid X_l \in C$ e $j \geq 1$.

		\begin{tcolorbox}
			Supponiamo di avere nella gramamtica $G$ che vogliamo trasformare la produzione
			$$ A \rightarrow B C a D $$
			e che l'insieme delle variabili cancellabili è $C = \{C, D\}$.

			Nella mia gramamtica $G'$ simulo la cancellazione di $C$ e $D$ aggiungendo le produzioni
			\begin{align*}
				A &\rightarrow B a D \\
				A &\rightarrow B C a \\
				A &\rightarrow B a \\
			\end{align*}
		\end{tcolorbox}

		\begin{tcolorbox}
			Supponiamo di avere nella gramamtica $G$ che vogliamo trasformare la produzone
			$$ A \rightarrow C D E $$
			e che l'insieme delle variabili cancellabili è $C = \{C, D, E\}$.

			Nella mia gramamtica $G'$ simulo la cancellazione di $C$ e $D$, quindi aggiungo le produzioni
			\begin{align*}
				A &\rightarrow C D \\
				A &\rightarrow C E \\
				A &\rightarrow D E \\
				A &\rightarrow C \\
				A &\rightarrow D \\
				A &\rightarrow E \\
			\end{align*}
		\end{tcolorbox}

		Visto che le produzioni da aggiungere sotto tutti i sottoinsiemi delle variabili cancellabili di un lato destro meno l'insieme vuoto, vengono aggiunge nel caso peggiore un numero esponenziale di produzioni.
	\item eliminazione delle produzioni unitarie: una produzione unitaria è una produzione della forma
		$$ A \rightarrow B, \hspace{1cm} A, B \in V $$
		Costruiamo similmente a prima l'insieme di tutte le coppie di variabili $X, Y$ tali per cui $X \overset{+}{\Rightarrow} Y$, cioè per cui vale
		Abbiamo quindi
		$$ X \rightarrow A_1 \rightarrow \dots \rightarrow Y $$
		questo processo infatti le catene sono di lunghezza al più $|V|$ senza contenere cicli.

		Nella nuova grammatica tolgo tutte le produzioni unitarie e se $X \rightarrow \dots \rightarrow Y \rightarrow \alpha$ e $\alpha \in \Sigma$ oppure $|\alpha| > 1$, allora aggiungo la produzione $X \rightarrow \alpha$.
	\item eliminazione simboli inutili: $X \in V \cup \Sigma$ è utile sse $\exists S \overset{*}{\Rightarrow} \alpha X \beta \overset{*}{\Rightarrow} w \in \Sigma^*$.
		Questi sono eliminati utilizzando algoritmi sui grafi (chiusura bottom up, chiusura top down, non lo ha spiegato ma ci sono negli appunti del Santini).
	\item eliminazione dei terminali: in tutte le produzioni $A \rightarrow \alpha$ con $|\alpha| > 1$ si introducono nonterminali per ogni terminale.
		\begin{tcolorbox}
			Supponiamo di avere le produzioni
			\begin{align*}
				A &\rightarrow A aab C \\
				A &\rightarrow b C \\
				A &\rightarrow b b \\
			\end{align*}
			introduciamo i nonterminali $X_a$ e $X_b$ e le regole
			\begin{align*}
				A &\rightarrow A X_a X_a X_b C \\
				A &\rightarrow X_b C \\
				A &\rightarrow X_b X_b \\
				X_a & \rightarrow a \\
				X_b & \rightarrow b
			\end{align*}
		\end{tcolorbox}
	\item binarizzazione delle produzioni: per ogni produzione $A \rightarrow B_1 B_2 \dots B_k$ con $k > 2$, si introducono delle produzioni intermedie
		\begin{align*}
			A &\rightarrow B_1 Z_1 \\
			Z_1 &\rightarrow B_2 Z_2 \\
			    &\vdots \\
			Z_{k - 2} &\rightarrow B_{k - 1} B_k
		\end{align*}
\end{enumerate}
\begin{tcolorbox}[breakable]
	Date le produzioni
	\begin{align*}
		S &\rightarrow a B \\
		S &\rightarrow b A \\
		A &\rightarrow a \\
		A &\rightarrow a S \\
		A &\rightarrow b A A \\
		B &\rightarrow b \\
		B &\rightarrow b S \\
		B &\rightarrow a B B \\
	\end{align*}
	questa è già priva di $\varepsilon$-produzioni, produzioni unitarie e tutti i simboli sono utili.

	Ora eliminiamo i terminali e otteniamo
	\begin{align*}
		S &\rightarrow X_a B \\
		S &\rightarrow X_b A \\
		A &\rightarrow a \\
		A &\rightarrow X_a S \\
		A &\rightarrow X_b A A \\
		B &\rightarrow b \\
		B &\rightarrow X_b S \\
		B &\rightarrow X_a B B \\
		X_a &\rightarrow a \\
		X_b &\rightarrow b \\
	\end{align*}
	ed ora binarizziamo le produzioni
	\begin{align*}
		S &\rightarrow X_a B \\
		S &\rightarrow X_b A \\
		A &\rightarrow a \\
		A &\rightarrow X_a S \\
		A &\rightarrow X_b E_1 \\
		E &\rightarrow A A \\
		B &\rightarrow b \\
		B &\rightarrow X_b S \\
		B &\rightarrow X_a E_2 \\
		E_2 &\rightarrow B B \\
		X_a &\rightarrow a \\
		X_b &\rightarrow b \\
	\end{align*}
\end{tcolorbox}

% lezione 15
% magari chapter invece che section
\section{Appartenenza ai Context Free di un linguaggio}
Dato un linguaggio ci possiamo chiedere se questo sia CF.
Ad esempio
$$ L = \{ a^l b^k c^j \mid k = j \} \overset{?}{\in} \text{CF} $$
Un linguaggio è CF se possiamo costruire una grammatica di tipo 2 o un automa a pila.
Ad esempio per il linguaggio di sopra possiamo consumare tutte le $a$ e controllare che il numero di $b$ e di $c$ sia uguale con una pila.

Prendiamo invece
$$ L = \{ a^i b^k c^j \mid i = j = j \} \overset{?}{\in} \text{CF} $$
L'automa per il linguaggio di prima non può essere adattato a questo linguaggio.

\begin{tcolorbox}[breakable]
	Prendiamo la grammatica
	\begin{align*}
		S &\rightarrow [S] \mid S S \mid T \\
		T &\rightarrow (T) \mid T T \mid \varepsilon
	\end{align*}
	e una derivazione
	$$ S \overset{*}{\Rightarrow} [()[]] $$
	Ora un albero di derivazione che possiamo fare per questa stringa è
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}[scale=1, every node/.style={transform shape}]
			\node (root) {$S$}
				[sibling distance=1cm]
				child { node {$[$} }
					child { node {$S$} 
						[sibling distance=3cm]
						child { node {$S$} 
							child { node {$T$} 
								[sibling distance=1cm]
								child { node {$($} }
								child { node {$T$} 
									child { node {$\varepsilon$} }
								}
								child { node {$)$} }
							}
						}
						child { node {$S$} 
							[sibling distance=1cm]
							child { node {$[$} }
							child { node {$S$} 
								child { node {$T$}
									child { node {$\varepsilon$} }
								}
							}
							child { node {$]$} }
						}
					}
				child { node {$]$} };

			\node[draw, fit=(root-2-1-1) (root-2-1-1-1) (root-2-1-1-2) (root-2-1-1-3) (root-2-1-1-2-1)] (bound1) {};
			\node[draw, fit=(root-2-2-2-1) (root-2-2-2-1-1)] (bound2) {};

			\node[left] at (bound1.west) {$T \overset{*}{\Rightarrow} ()$};
			\node[right] at (bound2.east) {$T \overset{*}{\Rightarrow} \varepsilon$};
		\end{tikzpicture}
	\end{figure}
	% fig 15.1
	sugli alberi di derivazione si possono fare operazione di sostituzione di sottoalberi, ad esempio nell'albero di sopra sostituenzo il sottoalbero 2 con il sottoalbero 1 otteniamo l'albero di derivazione per $[()[()]]$.
	In generale quello di sopra è un particolare albero che è rappresentato dalla derivazione
	$$ A \overset{*}{\Rightarrow} v A x, \hspace{1cm} v, x \in \Sigma^* $$
	questi sono interessanti perché possiamo ???.
	Ad esempio nell'albero prima abbiamo
	$$ S \overset{*}{\Rightarrow} [() S ] $$
	possiamo vedere che possiamo sia accorciare la derivazione
	% fig 15.2
	\begin{figure}[H]
		\centering
		\begin{subfigure}{\textwidth}
			\centering
			\begin{tikzpicture}[scale=1, every node/.style={transform shape}]
				\node (root) {$S$}
					[sibling distance=1cm]
					child { node {$[$} }
						child { node {$S$} 
							[sibling distance=3cm]
							child { node {$S$} 
								child { node {$T$} 
									[sibling distance=1cm]
									child { node {$($} }
									child { node {$T$} 
										child { node {$\varepsilon$} }
									}
									child { node {$)$} }
								}
							}
							child { node {$S$} 
								[sibling distance=1cm]
								child { node {$[$} }
								child { node {$S$} 
									child { node {$T$}
										child { node {$\varepsilon$} }
									}
								}
								child { node {$]$} }
							}
						}
					child { node {$]$} };

				\node[draw, fit=(root-2-2) (root-2-2-1) (root-2-2-2) (root-2-2-3) (root-2-2-2-1) (root-2-2-2-1-1)] (bound) {};
			\end{tikzpicture}
		\end{subfigure}
		\begin{subfigure}{0.45\textwidth}
			\centering
			\begin{tikzpicture}[scale=0.5, every node/.style={transform shape}]
				\node (root) {$S$}
					[sibling distance=1cm]
					child { node {$[$} }
						child { node {$S$} 
							[sibling distance=3cm]
							child { node {$S$} 
								child { node {$\dots$} }
							}
							child { node {$S$} 
								[sibling distance=1cm]
								child { node {$[$} }
								child { node {$S$} 
									child { node {$[$} }
									child { node {$S$} 
										child { node {$[$} }
										child { node {$S$} 
											child { node {$T$}
												child { node {$\varepsilon$} }
											}
										}
										child { node {$]$} }
									}
									child { node {$]$} }
								}
								child { node {$]$} }
							}
						}
					child { node {$]$} };
			\end{tikzpicture}
			\caption{Allungamento ($uv^2wx^2z$)}
		\end{subfigure}
		\begin{subfigure}{0.45\textwidth}
			\centering
			\begin{tikzpicture}[scale=0.5, every node/.style={transform shape}]
				\node (root) {$S$}
					[sibling distance=1cm]
					child { node {$[$} }
						child { node {$S$} 
							[sibling distance=3cm]
							child { node {$S$} 
								child { node {$\dots$} }
							}
							child { node {$S$} 
								[sibling distance=1cm]
								child { node {$T$}
									child { node {$\varepsilon$} }
								}
							}
						}
					child { node {$]$} };
			\end{tikzpicture}
			\caption{Accorciamento ($uwz$)}
		\end{subfigure}
	\end{figure}
	In questo modo possiamo generare infinite stringhe.
\end{tcolorbox}

\subsection{Pumping lemma}% TODO: posiziono bene 

Dal fatto che le grammatiche possono essere convertite in FNC (a patto di sacrificare la parola vuota), lavoreremo con grammatiche in FNC per semplificare la dimostrazione del pumping lemma.

Definiamo la \textit{profondità} (o altezza) di un albero come il più lungo cammino dalla radice ad una foglia.
\begin{lemma}
	Sia
	$$ G = \langle V, \Sigma, P, S \rangle $$
	una grammatica in FNC e sia $T : A \overset{*}{\Rightarrow} w \in \Sigma^*$ un albero di derivazione di altezza $h$.
	Allora la lunghezza di $w$ è minore o uguale a $2^{h - 1}$.
	$$ |w| \leq 2^{h - 1} $$
\end{lemma}
\begin{proof}
	Procediamo per induzione su $h$:
	\begin{itemize}
		\item per $h = 1$: per forza l'albero deve rappresentare una produzione della forma $A \rightarrow a \in \Sigma$, quindi $ w = a $ e 
			$$ |w| = 1 = 2^0 = 2^{1 - 1} $$
		\item la produzione applicata alla radice deve per forza essere della forma $A \rightarrow B C$, quindi l'albero si divide in due sottoalberi, un albero $T' : B \overset{*}{\Rightarrow} w'$ e un albero $T'' : C \overset{*}{\Rightarrow} w''$.
			\begin{center}
				\begin{tikzpicture}[
						PUNTO/.style={minimum size=0, inner sep=0, outer sep=0},
					]
					\node[PUNTO, label=above:{$A$}] at (0, 0) (top) {};

					\node[minimum size=5pt, inner sep=0, outer sep=0, circle, fill] at (2, -1) (top-right) {};
					\node[minimum size=5pt, inner sep=0, outer sep=0, circle, fill] at (-2, -1) (top-left) {};

					\node at (0, -1) {$T$};
					\node at (-2, -3) {$T'$};
					\node at (2, -3) {$T''$};


					\node[PUNTO] at (-4, -4) (bottom-left) {};
					\node[PUNTO] at (4, -4) (bottom-right) {};
					\node[PUNTO] at (0, -4) (bottom-center) {};

					\draw[-] (top) -- (top-left); 
					\draw[-] (top) -- (top-right); 
					\draw[-] (bottom-left) -- (bottom-right); 

					\draw[-] (top-left) -- (bottom-center);
					\draw[-] (top-right) -- (bottom-center);
					\draw[-] (top-right) -- (bottom-right);
					\draw[-] (top-left) -- (bottom-left);

					\draw[<->] ([xshift=-5pt] -4, -4) -- node[left] {$h - 1$} ([xshift=-5pt] -4, -1);
					\draw[<->] ([xshift=5pt] 4, -4) -- node[right] {$h$} ([xshift=5pt] 4, 0);

					\draw[dashed, -] (-4, -1) -- (top-left);
					\draw[dashed, -] (4, 0) -- (top);

					\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] ([yshift=-5pt] bottom-left.south) to node[below, yshift=-0.2cm] {\tiny $w'$} ([yshift=-5pt] bottom-center.south);
					\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] ([yshift=-5pt] bottom-center.south) to node[below, yshift=-0.2cm] {\tiny $w''$} ([yshift=-5pt] bottom-right.south);
					\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] ([yshift=-20pt] bottom-left.south) to node[below, yshift=-0.2cm] {\tiny $w$} ([yshift=-20pt] bottom-right.south);
				\end{tikzpicture}
			\end{center}
			% fig 15.3
			Questi due hanno altezza minore o uguale ad $h - 1$.
			Ora applicando l'ipotesi induttiva 
			\begin{align*}
				|w'| &\leq 2^{h - 2} \\
				|w''| &\leq 2^{h - 2}
			\end{align*}
			e 
			$$ |w| = |w'| + |w''| \leq 2^{h - 2} + 2^{h - 2} = 2^{h - 1} $$
	\end{itemize}
\end{proof}

\begin{lemma}[Pumping lemma per CFL]
	Sia $L$ un linguagio CF allora $\exists N > 0$ tale che $\forall z \in L$ con $|z| \geq N$, questa può essere scomposta
	$$ z = uvwxy $$
	tali che
	\begin{enumerate}
		\item $|vwx| \leq N $
		\item $vx \neq \varepsilon $
		\item $\forall i \geq 0 \mid uv^i w x^i y \in L$
	\end{enumerate}
\end{lemma}
\begin{proof}
	Sia $G = \langle V, \Sigma, P, S \rangle$ una grammatica in FNC per $L \setminus \{ \varepsilon \}$.
	Sia $k = | V | $ e definiamo $N = 2^k$.

	Sia $z \in L$ con $|z| \geq N$, allora ha un albero di derivazione $T : S \overset{*}{\Rightarrow} z$
	\begin{center}
		\begin{tikzpicture}[
				PUNTO/.style={minimum size=0, inner sep=0, outer sep=0},
			]
			\node[PUNTO, label=above:{$S$}] at (0, 0) (top) {};

			\node[PUNTO] at (2, -4) (top-right) {};
			\node[PUNTO] at (-2, -4) (top-left) {};

			\draw[-] (top) -- (top-left); 
			\draw[-] (top) -- (top-right); 
			\draw[-] (top-left) -- (top-right); 

			\draw[<->] ([xshift=5pt] 3, -4) -- node[right] {$\geq k + 1$} ([xshift=5pt] 3, 0);
			\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] ([yshift=-5pt] top-left.south) to node[below, yshift=-0.2cm] {$z$} ([yshift=-5pt] top-right.south);
		\end{tikzpicture}
	\end{center}
	% fig 15.4
	visto che la lunghezza di $z$ è maggiore di $2^k$, allora dal lemma precedente abbiamo che l'altezza di $T$ è almeno $k + 1$, quindi esiste un cammino dalle foglie alle radici da $k + 1$ archi, quindi $k + 2$ nodi.
	Visto che l'ultimo nodo è un terminale, durante questo cammino incontreremo $k + 1$ non terminali, e quindi almeno un non terminale si ripeterà in questo percorso.
	Sia $A$ questo non terminale.
	\begin{figure}[H]
		\centering
		\begin{subfigure}{\textwidth}
			% sistemo label sotto pattern
			\centering
			\begin{tikzpicture}[
					PUNTO/.style={minimum size=0, inner sep=0, outer sep=0},
				]
				\node[circle, fill, minimum size=1pt, inner sep=1pt, label=above:{$S$}] at (0, 0) (top-1) {};
				\node[circle, fill, minimum size=1pt, inner sep=1pt, label=left:{$A$}] at (0, -2) (top-2) {};
				\node[circle, fill, minimum size=1pt, inner sep=1pt, label=right:{$A$}] at (0, -4) (top-3) {};

				\node[PUNTO] at (4, -6) (right-1) {};
				\node[PUNTO] at (2.66666, -6) (right-2) {};
				\node[PUNTO] at (1.33333, -6) (right-3) {};
				\node[PUNTO] at (-4, -6) (left-1) {};
				\node[PUNTO] at (-2.66666, -6) (left-2) {};
				\node[PUNTO] at (-1.33333, -6) (left-3) {};

				\path[name path=T21] (right-2) -- (top-2) -- (left-2);
				\path[name path=T22] (right-2) -- (left-2);
				\path[name path=T31] (right-3) -- (top-3) -- (left-3);
				\path[name path=T32] (right-3) -- (left-3);
				\tikzfillbetween[of=T21 and T22]{pattern={Lines[angle=45,distance={3pt/sqrt(2)}]},pattern color=gray, line width=0.2pt};
				\tikzfillbetween[of=T31 and T32]{white};
				\tikzfillbetween[of=T31 and T32]{pattern={crosshatch dots}, pattern color=gray, radius=0.1pt};

				\draw[-] (top-1) -- (left-1);
				\draw[-] (left-1) -- (right-1);
				\draw[-] (right-1) -- (top-1);
				\draw[-] (top-2) -- (left-2);
				\draw[-] (right-2) -- (top-2);
				\draw[-] (top-3) -- (left-3);
				\draw[-] (right-3) -- (top-3);


				\path[draw, -] (top-1) -- (-0.3, -0.75) -- (0.5, -1.25) -- (top-2) -- (-0.3, -2.75) -- (0.5, -3.25) -- (top-3);

				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] ([yshift=-5pt] left-1.south) to node[below, yshift=-0.2cm] {\tiny $u$} ([yshift=-5pt] left-2.south);
				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] ([yshift=-5pt] left-2.south) to node[below, yshift=-0.2cm] {\tiny $v$} ([yshift=-5pt] left-3.south);
				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] ([yshift=-5pt] left-3.south) to node[below, yshift=-0.2cm] {\tiny $w$} ([yshift=-5pt] right-3.south);
				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] ([yshift=-5pt] right-3.south) to node[below, yshift=-0.2cm] {\tiny $x$} ([yshift=-5pt] right-2.south);
				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] ([yshift=-5pt] right-2.south) to node[below, yshift=-0.2cm] {\tiny $y$} ([yshift=-5pt] right-1.south);

				\draw[<->] ([xshift=5pt] 4, -6) -- node[right] {$\geq k + 1$} ([xshift=5pt] 4, 0);


			\end{tikzpicture}
		\end{subfigure}
		\begin{subfigure}{0.4\textwidth}
			\centering
			\begin{tikzpicture}[
					PUNTO/.style={minimum size=0, inner sep=0, outer sep=0}, 
					scale=0.45, 
					every node/.style={transform shape}
				]
				\node[PUNTO] at (0, 0) (top-1) {};
				\node[PUNTO] at (0, -2) (top-2) {};
				\node[PUNTO] at (0, -4) (top-3) {};
				\node[PUNTO] at (0, -6) (top-4) {};

				\node[PUNTO] at (4, -6) (right-1) {};
				\node[PUNTO] at (2.66666, -6) (right-2) {};
				\node[PUNTO] at (2.66666, -8) (right-3) {};
				\node[PUNTO] at (1.33333, -8) (right-4) {};

				\node[PUNTO] at (-4, -6) (left-1) {};
				\node[PUNTO] at (-2.66666, -6) (left-2) {};
				\node[PUNTO] at (-2.66666, -8) (left-3) {};
				\node[PUNTO] at (-1.33333, -8) (left-4) {};

				\path[name path=T21] (right-2) -- (top-2) -- (left-2);
				\path[name path=T22] (right-2) -- (left-2);

				\path[name path=T31] (right-3) -- (top-3) -- (left-3);
				\path[name path=T32] (right-3) -- (left-3);

				\path[name path=T41] (right-4) -- (top-4) -- (left-4);
				\path[name path=T42] (right-4) -- (left-4);

				\tikzfillbetween[of=T21 and T22]{pattern={Lines[angle=45,distance={3pt/sqrt(2)}]},pattern color=gray, line width=0.2pt};
				\tikzfillbetween[of=T31 and T32]{white};
				\tikzfillbetween[of=T31 and T32]{pattern={Lines[angle=45,distance={3pt/sqrt(2)}]}, pattern color=gray, line width=0.2pt};
				\tikzfillbetween[of=T41 and T42]{white};
				\tikzfillbetween[of=T41 and T42]{pattern={crosshatch dots}, pattern color=gray, radius=0.1pt};
				\draw[fill=black] (top-1) circle[radius=1pt];
				\draw[fill=black] (top-2) circle[radius=1pt]; 
				\draw[fill=black] (top-3) circle[radius=1pt];
				\draw[fill=black] (top-4) circle[radius=1pt];

				\node [above=of top-1, yshift=-25pt] {$S$};
				\node [above=of top-2, yshift=-25pt] {$A$};
				\node [above=of top-3, yshift=-25pt] {$A$};
				\node [above=of top-4, yshift=-25pt] {$A$};

				\draw[-] (top-1) -- (left-1);
				\draw[-] (right-1) -- (top-1);
				\draw[-] (top-2) -- (left-2);
				\draw[-] (right-2) -- (top-2);
				\draw[-] (top-3) -- (left-3);
				\draw[-] (right-3) -- (top-3);
				\draw[-] (right-3) -- (left-3);
				\draw[-] (top-4) -- (left-4);
				\draw[-] (top-4) -- (right-4);
				\draw[-] (left-1) -- (-1.33333, -6);
				\draw[-] (right-1) -- (1.33333, -6);
			\end{tikzpicture}
			\caption{Allungamento}
		\end{subfigure}
		\begin{subfigure}{0.4\textwidth}
			\centering
			\begin{tikzpicture}[
					PUNTO/.style={minimum size=0, inner sep=0, outer sep=0}, 
					scale=0.45, 
					every node/.style={transform shape}
				]
				\node[PUNTO] at (0, 0) (top-1) {};
				\node[PUNTO] at (0, -2) (top-2) {};

				\node[PUNTO] at (4, -6) (right-1) {};
				\node[PUNTO] at (1.33333, -4) (right-2) {};

				\node[PUNTO] at (-4, -6) (left-1) {};
				\node[PUNTO] at (-1.33333, -4) (left-2) {};

				\path[name path=T21] (right-2) -- (top-2) -- (left-2);
				\path[name path=T22] (right-2) -- (left-2);

				\tikzfillbetween[of=T21 and T22]{white};
				\tikzfillbetween[of=T21 and T22]{pattern={crosshatch dots}, pattern color=gray, radius=0.1pt};

				\draw[fill=black] (top-1) circle[radius=1pt];
				\draw[fill=black] (top-2) circle[radius=1pt]; 

				\node [above=of top-1, yshift=-25pt] {$S$};
				\node [above=of top-2, yshift=-25pt] {$A$};

				\draw[-] (top-1) -- (left-1);
				\draw[-] (right-1) -- (top-1);
				\draw[-] (right-2) -- (left-2);
				\draw[-] (top-2) -- (-2.66666, -6);
				\draw[-] (top-2) -- (2.66666, -6);
				\draw[-] (left-1) -- (-2.66666, -6);
				\draw[-] (right-1) -- (2.66666, -6);
			\end{tikzpicture}
			\caption{Accorciamento}
		\end{subfigure}
	\end{figure}
	% fig 15.5
	Per questo non terminale $A$ vale
	\begin{align*}
		A &\overset{*}{\Rightarrow} w \\
		A &\overset{*}{\Rightarrow} v A x \\
		S &\overset{*}{\Rightarrow} u A y \\
	\end{align*}
	è facile vedere che 
	$$ S \overset{*}{\Rightarrow} u A y \overset{*}{\Rightarrow} u v A x y \overset{*}{\Rightarrow} \dots \overset{*}{\Rightarrow} u v^i A x^i y \overset{*}{\Rightarrow} u v^i w x^i y $$
	quindi abbiamo dimostrato il punto 3.

	La produzione centrale di $A$ deve essere per forza della forma $A \rightarrow B C$, supponiamo che $C$ sia il non terminale sul percorso più lungo che genera $w x$, allora visto che siamo in FNC e non possiamo generare la parola vuota, allora per forza $B$ genera qualcosa diverso da $\varepsilon$, quindi abbiamo dimostrato il punto 2.

	L'altezza della parte dell'albero che genera $vwx$ è al massimo $k + 1$, cioè il numero massimo di nodi che possiamo vedere prima di trovare una ripetizione.
	Quindi utilizzando ancora il lemma di sopra, $|vwx| \leq N$.
\end{proof}
\begin{tcolorbox}[breakable]
	Riprendiamo il linguaggio di prima
	$$ L = \{ a^n b^n c^n \mid c \geq 0 \} $$
	mostriamo che non soddifsa il pumping lemma.

	Supponiamo per assurdo che $L$ sia CF e mostriamo che non può esistere una costante $N$ per cui valga il pumping lemma.
	Sia $N$ la costante di $L$, prendiamo
	$$ z = a^N b^N c^N = u v w x y $$
	Visto che per la prima condizione $|vwx| \leq N$, $vwx$ potrà contenere solo due dei tre simboli, più precisamente $vwx \in a^* b^*$ o $vwx \in b^* c^*$.
	Supponiamo che $vwx \in a^* b^*$, prendiamo $i = 0$ e la stringa $z' = uwy$, questa per la condizione 3 dovrebbe essere in $L$.
	Calcoliamo ora le occorrenze dei simboli in $z'$:
	\begin{align*}
		\#_c(z') &= N \\
		\#_a(z') + \#_b(z') &= 2N - (\#_a(vx) + \#_b(vx)) \\
		                     &\leq 2N \tag*{\tiny Per la condizione 2 $(\#_a(vx) + \#_b(vx)) \geq 1$}
	\end{align*}
	e quindi $z' = a^k b^j c^N \not \in L$ con $k, j < N$, quindi abbiamo un assurdo.
\end{tcolorbox}

\begin{tcolorbox}[breakable]
	Prendiamo il linguaggio
	$$ L = \{ w w \mid w \in \{a, b\}^* \} $$
	questo non è CF.

	Mostriamolo ancora attraverso il pumping lemma.
	Sia $N$ la costante del pumping lemma, scegliamo la stringa
	$$ z = a^N b^N a^N b^N \in L = u v w x y $$
	Utilizznado ancora la condizione 1 abbiamo due casi
	\begin{itemize}
		\item $vwx \in a^* b^* $, prendiamo la stringa $z' = u w x$, questa dovrebbe essere in $L$ per la condizione 3.
			Questa è $z' = a^N b^{N'} a^{N''} b^N$, con $N' \leq N, N'' \leq N$, ora possono essere diminuite solo le $a$, solo le $b$ o entrambe, ma in ogni caso $z' \not \in L$.
		\item $vwx \in b^* a^*$, questo a sua volta dsi divide in due casi, in base al fatto che $vwx$ sia nella prima o nella seconda parte della stringa.
			Prendendo ancora $i = 0$, $z' = a^{N'} b^{N''} a^N b^N$, con $N' \leq N$ e $N'' \leq N$, con ancora almeno uno tra $N'$ e $N''$ minore o uguale a $N$.
	\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[breakable]
	Prendiamo il linguaggio
	$$ L = \{ a^h b^j a^k \mid j = \max(h, k) \} $$
	supponiamo sia CF e chiamiamo $N$ la costante del pumping lemma.
	Prendiamo la stringa
	$$ z = a^N b^N a^N  \in L = u v w x y $$
	Anche qui ci sono due casi
	\begin{itemize}
		\item $vwx \in a^* b^*$, sappiamo che $vx \neq \varepsilon$, distinguiamo tre casi
			\begin{itemize}
				\item $vx \in a^+$, prendendo $i = 2$, otteniamo $z' = a^{N'} b^N a^N$, con $N' > N$, che non fa parte di $L$
				\item $vx \in b^+$, prendendo $i = 0$, otteniamo $z' = a^N b^{N'} a^N$, con $N' < N$, che non fa parte di $L$
				\item $vwx \in a^+b^+$, prendendo $i = 0$, otteniamo $z' = a^{N'} b^{N''} a^N$, con $N'' < N$, che non fa parte di $L$
			\end{itemize}
		\item $vwx \in b^* a^*$, questo caso è simmetrco al precedente
	\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}
	Prendiamo il linguaggio
	$$ L = \{ a^n b^n c^l \mid k \neq n \} $$
	è un linguaggio che rispetta il pumping lemma, ma non è CF.
	% vedremo la prossima lezione.
\end{tcolorbox}

% lezione 16
Bisogna trovare un $i$ tale per cui 
$$ m + (i - 1)(l + r) $$
per cui la somma non sia un numero primo.
Scegliendo $i = m + 1$, allora 
$$ m + m(l + r) = m(l + r + 1) $$
non è primo.

\begin{nota}
Se l'alfabeto è di una lettera sola, non c'è differenza tra regolari e context free.
\end{nota}

\subsection{Lemma di Odgen}

\begin{tcolorbox}[breakable]
Sia
$$ \mathcal{L} = \{ a^n b^n c^k \mid k \neq n \} $$
Intuitivamente non è CF, infatti posso usare una pila per confrontare le $a$ e le $b$, ma una volta fatto questo ho perso l'informazione su $n$.

Mostriamolo con il pumping lemma. 
Scegliamo fissiamo la costante $N$ e una scegliamo una stringa
	$$ z = a^m b^m c^j = u v w x y  \in \mathcal{L} \text{t.c.} |z| \geq N $$
quindi $2m + j \geq N$.

Analizziamo la composizione di $vwx$:
\begin{itemize}
	\item $vwx \in a^+$, questo è facilmente risolvibile mostrando che se si aumentano o diminuiscono le $a$ il loro numero diventa diverso da quello delle $b$
	\item $vwx \in b^+$, è analogo al caso di sopra
	\item $vwx \in c^+$, se $j = 1$ allora facilmente possiamo fissare una $i$ tale che rende il numero delle $c$ uguale a $m$
		Alternativamente possiamo mostrare un caso non valido anche con la stringa 
		$$ z = a^{N + N!} b^{N + N!} c^N $$
		se assumiamo che $|vx| = k$, in
		$$ u v^i w x^i y = a^{N + N!} b^{N + N!} c^{N + k(i - 1)} $$
		e $0 < k \leq N$, vogliamo che $k(i - 1) = N!$, quindi scegliamo $i - 1 = \frac{N!}{k}$, cioè
		$$ i = 1 + \frac{N!}{k} $$
	\item $vwx \in a^+b^+$, questo a sua volta si divide in vari sottocasi
		\begin{itemize}
			\item $v \in a^+ b^+$, cioè il confine tra $a$ e $b$ cade in $v$, è facile mostrare che $v^i$ sarebbe una stringa composta da $a$ seguite da $b$ seguite ancora da $a$ e così via
			\item $w \in a^+ b^+$, allora $v \in a^*$ e $x \in b^*$ abbiamo ancora altri casi
				\begin{itemize}
					\item se $v$ e $x$ sono di dimensione diversa è facile
					\item se $v$ e $x$ sono di dimensione uguale, cioè
						$$ v = a^h, b = b^h $$
				\end{itemize}
		\end{itemize}
\end{itemize}
In questo esempio il pumping lemma non si può applicare. % ???

\end{tcolorbox}

Sia $T$ un albero con alcune foglie marcate.
E definiamo dei nodi interni speciali detti \textit{branch point} definiti come nodi che hanno almeno due figli marcati o due figli con discendenti marcati.
Definiamo i \textit{nodi speciali} come tutti i branch point e i nodi che hanno almeno un figlio marcato.
% 16.1
\begin{center}
	% rendo più distinguibili i nodi di diverso tipo (e.g. bianco e nero)
	\begin{tikzpicture}[
			MARKED/.style={fill=red, circle, inner sep=2pt},
			BP/.style={fill=yellow, circle, inner sep=2pt},
			SPECIAL/.style={fill=orange, circle, inner sep=2pt},
			NORMAL/.style={draw, fill=white, circle, inner sep=2pt},
			scale=.6, every node/.style={transform shape}
		]
		\node[NORMAL] (root) {}
			[sibling distance=6cm]
			child { 
				[sibling distance=4.5cm]
				node[BP] {}
				child {
					[sibling distance=1.5cm]
					node[NORMAL] {}
					child {
						node[BP] {}
						child {
							node[NORMAL] {}
							child { 
								node[SPECIAL] {} 
								child { node[MARKED] {} } 
							}
							child { node[NORMAL] {} }
						}
						child { node[MARKED] {} }
					}
					child { node[NORMAL] {} }
				}
				child {
					 [sibling distance=2cm]
					 node[BP] {}
					 child {
						[sibling distance=1cm]
						node[NORMAL] {}
						child { node[NORMAL] {} }
						child { 
							node[NORMAL] {}
							child {
								node[NORMAL] {}
					 			child {
									node[SPECIAL] {}
					 				child { node[MARKED] {} }
					 			}
							}
						}
						child { node[NORMAL] {} }
					 }
					 child {
					 	[sibling distance=1cm]
						node[NORMAL] {}
					 	child[missing]
					 	child {
							node[NORMAL] {}
							child { node[NORMAL] {} }
					 		child {
					 			node[SPECIAL] {}			
					 			child { node[MARKED] {} }
								child { node[NORMAL] {} }
					 		}
						}
					}
				}
			}
			child { 
				[sibling distance=2cm]
				node[NORMAL] {}
			 	child { node[NORMAL] {} 
					child { node[NORMAL] {} }
				}
				child { 
					node[NORMAL] {}
					child {
						node[NORMAL] {}
						child { node[NORMAL] {} }
					}
				}
			};
		\node at (4, -8) {
			\begin{tblr}{|cl|}
				\hline
				\textcolor{red}{$\blacksquare$} & Nodi marcati \\
				\textcolor{orange}{$\blacksquare$} & Nodi speciali \\
				\textcolor{yellow}{$\blacksquare$} & Branch point \\
				\hline
			\end{tblr}
		};
	\end{tikzpicture}
\end{center}
supponiamo di marcare un altro nodo
% 16.2
\begin{center}
	% rendo più distinguibili i nodi di diverso tipo (e.g. bianco e nero)
	\begin{tikzpicture}[
			MARKED/.style={fill=red, circle, inner sep=2pt},
			BP/.style={fill=yellow, circle, inner sep=2pt},
			SPECIAL/.style={fill=orange, circle, inner sep=2pt},
			NORMAL/.style={draw, fill=white, circle, inner sep=2pt},
			scale=.6, every node/.style={transform shape}
		]
		\node[BP] (root) {}
			[sibling distance=6cm]
			child { 
				[sibling distance=4.5cm]
				node[BP] {}
				child {
					[sibling distance=1.5cm]
					node[NORMAL] {}
					child {
						node[BP] {}
						child {
							node[NORMAL] {}
							child { 
								node[SPECIAL] {} 
								child { node[MARKED] {} } 
							}
							child { node[NORMAL] {} }
						}
						child { node[MARKED] {} }
					}
					child { node[NORMAL] {} }
				}
				child {
					 [sibling distance=2cm]
					 node[BP] {}
					 child {
						[sibling distance=1cm]
						node[NORMAL] {}
						child { node[NORMAL] {} }
						child { 
							node[NORMAL] {}
							child {
								node[NORMAL] {}
					 			child {
									node[SPECIAL] {}
					 				child { node[MARKED] {} }
					 			}
							}
						}
						child { node[NORMAL] {} }
					 }
					 child {
					 	[sibling distance=1cm]
						node[NORMAL] {}
					 	child[missing]
					 	child {
							node[NORMAL] {}
							child { node[NORMAL] {} }
					 		child {
					 			node[SPECIAL] {}			
					 			child { node[MARKED] {} }
								child { node[NORMAL] {} }
					 		}
						}
					}
				}
			}
			child { 
				[sibling distance=2cm]
				node[NORMAL] {}
			 	child { node[NORMAL] {} 
					child { node[NORMAL] {} }
				}
				child { 
					node[NORMAL] {}
					child {
						node[SPECIAL] {}
						child { node[MARKED] {} }
					}
				}
			};
	\end{tikzpicture}
\end{center}
\begin{lemma}
  	Sia $G = \langle V, \Sigma, P, S\rangle$ una grammatica in FNC e prendiamo un albero di derivazione 
  	$$A \overset{*}{\Rightarrow} w, \hspace{1cm} A \in V, w \in \Sigma^* $$
  	e $w$ contiene alcune posizioni marcate.
  
  	Se il numero massimo di nodi speciali su un cammino dalla radice alle foglie è minore o uguale a $k$, allora il numero di posizioni marcate in $w$ è $\leq 2^k - 1$.
\end{lemma}
Questo è una generalizzazione del lemma della lezione precedente, nell'altro supponevamo marcata l'intera stringa.
% 
\begin{proof}
 	Procediamo per induzione su $k$
 	\begin{itemize}
 		\item $k = 1$, quindi in ogni cammino dalla radice ad una foglia esiste al massimo un nodo speciale.
 			% 16.3
 			Supponiamo che questo nodo speciale sia un branch point
 			% 16.4
 			ma questo non può valere visto che in FNC l'unica produzione che può generare un terminale è della forma $C \Rightarrow a$, quindi anche questi due dovrebbero essere nodi speciali.
 			Quindi esiste una singola foglia marcata, infatti se ne esistesse più di una, allora il loro nodo in comune sarebbe un branch point.
 		\item supponiamo che sia vero per valori $< k$, e mostriamo che è vero per $k$.
 			% 16.5
 			Fermiamoci al primo nodo speciale dalla radice, e che questo sia un branch point, per ipotesi induttiva nell'abero di sinistra e di destra ci saranno al massimo $2^{k - 2}$ posizioni marcate.
 			Inoltre $z_0$ e $z_3$ non possono avere posizioni marcate, altrimenti il branch point sarebbe più in alto.
 			Quindi $\leq 2^{k - 2} + 2^{k - 2} = 2^{k - 1}$.
	\end{itemize}
\end{proof}

\begin{lemma}[Lemma di Ogden]
	\label{lemma:ogden}
	Sia $L \in \text{CF}$, allora esiste una costante $N$ tale che per ogni $z \in L$ sono marcate $N$ posizioni e possiamo scomporre $z$ tale che
	$$ z = u v w x y $$
	tale che
	\begin{itemize}
		\item $vx$ contiene almeno una posizione marcata
		\item $vwx$ contiene al più $N$ posizioni marcate
		\item per ogni $i > 0$, $u v^i w x^i y \in L$
	\end{itemize}
\end{lemma}
Quindi il pumping lemma è un caso speciale di questo in cui ogni posizione è marcata.
\begin{proof}
	Sia $G = \langle V, \Sigma, S, P \rangle$ una grammatica in FNC, definiamo $k = |V|$ e fissiamo $N = 2^k$.
	Prendiamo una stringa $z \in L$ con almeno $N$ nodi marcati.
	Prendiamo il cammino dalle foglie alla radice che contiene il maggior numero di nodi speciali.
	In base al lemma di prima, il massimo numero di nodi speciali sul cammino è $\geq k + 1$.
	Percorrendo il cammino e leggendo le variabili che compaiono sui nodi speciali, sia questa $A$, troveremo almeno una ripetizione.
	I sottoalberi di questa coppia di definisce le nostre parti $u, v, w, x$ e $y$.

	Visto che la prima occorrenza di $A$ sarà un branch point, questa sarà una produzione del tipo $A \rightarrow BC$, uno dei due rami potrerà alla seconda $A$ e sicuramente il secondo porterà ad una foglia marcata, quindi in $v$ e $x$ c'è almeno un branch point.
\end{proof}

Con questo nuovo lemma proviamo a dimostrare l'esempio di prima
\begin{tcolorbox}[breakable]
	Sia
	$$ L = \{ a^n b^n c^k \mid k \neq n \} $$
	con $N$ costante per $L$.
	La stringa con cui si può arrivare ad un assurdo è
	$$ z = a^N b^N c^{N + N!} = uvwxy $$
	con tutte le $a$ marchiate.

	Visto che $vx$ deve contenere almeno una posizione marcata, allora questo deve avere almeno una $a$ al suo interno.
	Questo ci restringe ai tre casi
	\begin{itemize}
		\item $vwx \in a^+$, il numero di $a$ cresce, ma non il numero di $b$
		\item $vwx \in a^+ b^+$, si divide in alcuni sottocasi in base a dove il confine tra le $a$ e $b$ cade
			\begin{itemize}
				\item $v \in a^+ b^+$, ripetere $v$ fa sì che la stringa perda la struttura e porta ad avere $a$ dopo le $b$
				\item analogo a sopra se il confine si trova su $x$
				\item $v \in a^+$ e $x \in b^+$, supponiamo più precisamente che
					$$ v = a^l, x = b^r $$
					\begin{itemize}
						\item se $l \neq r$ è ovvio che la stringa non sia valida, anche solo per $i = 0$ cancellerei un numero diverso di $a$ e di $b$
						\item se $l = r$, la stringa che otterremmo ripetendo $i$ volte sarebbe
							$$ a^{N + l(i - 1)} b^{N + l(r - 1)} c^{N + N!} $$
							se si scegle $i = 1 + \frac{N!}{l}$ allora otteniamo che le $a$ e le $b$ sono uguali al numero di $c$ e $N!$ è sicuramente divisibile da $l$.
					\end{itemize}
			\end{itemize}
		\item $vwx \in a^+ b^N c^+ $, 
			\begin{itemize}
				\item se $v$ e $x$ contengono tipi di lettere diverse, come prima ripetendo si perde la struttura
				\item per il resto si tratta in maniera analogo a il secondo caso
			\end{itemize}
	\end{itemize}
\end{tcolorbox}

% esercizi
\begin{tcolorbox}[breakable]
	Sia
	$$ \mathcal{L} = \{ a^p b^q c^r \mid p = q \vee q = r \} $$
	e 
	$$ \mathcal{L} = \{ a^p b^q c^r \mid p = q \otimes q = r \} $$
\end{tcolorbox}

% lezione 17
\section{Ambiguità}
Prendiamo il linguaggio
$$ \mathcal{L} = \{ a^p b^q c^r \mid p = q \vee q = r \} $$
sappiamo gli automi per $a^n b^n c^m$ e per $a^m b^n c^n$, % ref ?
quindi nondeterministicamente all'inizio scegliamo quale strada prendere nell'automa.
Lo stesso si può fare con una grammatica
$$ S \rightarrow S' C \mid A S'' $$
dove $S' \rightarrow a S' b \mid \varepsilon $ genera $a^n b^n$
e $S'' \rightarrow b S'' c \mid \varepsilon $ genera $b^n c^n$
e 
\begin{align*}
	C &\rightarrow c C \mid \varepsilon \\
	A &\rightarrow a A \mid \varepsilon \\
\end{align*}
\begin{center}
	\begin{tikzpicture}
		\node {$S$}
			[sibling distance=3cm, level distance=1cm]
			child {
				node {$S'$}
				[sibling distance=1cm]
				child { node {$a$} }
				child {
					node {$S'$}
					child { node {$\varepsilon$} }
				}
				child { node {$b$} }
			}
			child {
				node {$C$}
				[sibling distance=1cm]
				child { node {$c$} }
				child {
					node {$C$}
					child { node {$c$} }
					child { 
						node {$C$} 
						child { node {$\varepsilon$} }
					}
				}
			};
	\end{tikzpicture}
\end{center}
% fig 17.1
vediamo ora i casi particolari dei due alberi
\begin{figure}[H]
	\centering
	\begin{subfigure}{.45\textwidth}
		\begin{tikzpicture}
			\node {$S$}
				[sibling distance=3cm, level distance=1cm]
				child {
					node {$S'$}
					[sibling distance=1cm]
					child { node {$a$} }
					child {
						node {$S'$}
						child { node {$a$} }
						child {
							node {$S'$}
								child { node {$\varepsilon$} }
						}
						child { node {$b$} }
					}
					child { node {$b$} }
				}
				child {
					node {$C$}
					[sibling distance=1cm]
					child { node {$c$} }
					child {
						node {$C$}
						child { node {$c$} }
						child { 
							node {$C$} 
							child { node {$\varepsilon$} }
						}
					}
				};
		\end{tikzpicture}
	\end{subfigure}
	\begin{subfigure}{.45\textwidth}
		\begin{tikzpicture}
			\node {$S$}
				[sibling distance=3cm, level distance=1cm]
				child {
					node {$A$}
					[sibling distance=1cm]
					child { node {$a$} }
					child {
						node {$A$}
						child { node {$a$} }
						child {
							node {$A$}
							child { node {$\varepsilon$} }
						}
					}
				}
				child {
					node {$S''$}
					[sibling distance=1cm]
					child { node {$b$} }
					child {
						node {$S''$}
						child { node {$b$} }
						child { 
							node {$S''$}
							child { node {$\varepsilon$} }
						}
						child { node {$c$} }
					}
					child { node {$c$} }
				};
		\end{tikzpicture}
	\end{subfigure}
	\caption{Alberi per la stringa $a^2 b^2 c^2$}
\end{figure}
Entrambi gli alberi rappresentano derivazioni leftmost che generano la stessa stringa $a^2 b^2 c^2$. % mostro magari le due derivazioni leftmost

Una grammatica viene detta \textit{ambigua} se esiste almeno una stringa che può essere generata in due modi diversi.
\begin{definizione}[Grado di ambiguità]
	Chiamiamo il \textit{grado di ambiguità} di una stringa $w \in \Sigma^*$ in $G$ è uguale al numero di alberi di derivazione di $w$ in $G$.
	Ed il grado di ambiguità di $G$ è il massimo grado di ambiguità generato dalle stringhe della grammatica.
\end{definizione}

Non sempre si può trovare una grammatica non ambigua per un linguaggio.
Esistono linguaggi detti \textit{inerentemente ambigui}, cioè per cui ogni grammatica di tipo 2 che li genera sarà ambigua.

Utilizzando il lemma di Ogden mostreremo che il linguaggio $L$ è interentemente ambiguo.
Mostriamo prima una versione alternativa del lemma
\begin{lemma}[Lemma di Ogden]
	Sia $G$ una grammatica CF e sia $L = L(G)$.
	Esiste una costante $N$ tale che per ogni $z \in L$ con almeno $N$ posizioni marcate possiamo decomporre $z$ in 5 parti
	$$ z = uvwxy $$
	tali che
	\begin{enumerate}
		\item $vwx$ contiene al più $N$ posizioni marcate
		\item $vx$ contiene almeno una posizione marcata
		\item esiste una variabile $A \in V$ tale che $S \overset{*}{\Rightarrow} uAy$, e $A \overset{*}{\Rightarrow} vAx$ e $A \overset{*}{\Rightarrow} w$.
			E dunque per ogni $i \geq 0$ $u v^i w x^i y \in L$.
	\end{enumerate}
\end{lemma}
Noi il teorema di Ogden lo abbiamo dimostrato utilizzando grammatiche in CNF, si può fare anche per grammatiche generiche, ma è più tedioso.

\begin{proof}[Ambiguità di $L$]
	Noi vogliamo dimostrare che
	$$ \mathcal{L} = \{ a^p b^q c^r \mid p = q \vee q = r \} $$
	è inerentemente ambiguo.
	
	Sia $G$ una qualunque grammatica CF per $\mathcal{L}$.
	Sia $N$ la costante del lemma di Ogden e $m = \max(N, 3) $ il massimo tra $N$ e 3.
	Prendiamo 
	$$ z = a^m b^m c^{m + m!} \in \mathcal{L}$$
	e marchiamo tutte le $a$.

	Prendiamo la stringa$\alpha$ ottenuta ponendo $i = 2$, cioè la stringa $\alpha = u v^2 w x^2 y \in \mathcal{L}$.
	Contiamo le $b$ in $\alpha$
	\begin{align*}
		\#_b(\alpha) &= \underbrace{\#_b(z)}_{m} + \underbrace{\#_b(vx)}_{\leq m} \\
		&\leq 2m \\ 
		&< m + m! \tag{Visto che $m$ è almeno 3} \\
		&\leq \#_c(\alpha) \tag{Le $c$ rimaste sono almeno quelle che c'erano prima}
	\end{align*}
	e visto che $uv^2 w x^2 y \in \mathcal{L}$ allora $\#_b(\alpha) = \#_a(\alpha)$ e per la proprietà 2 del lemma di Ogden $\#_a(vx) = \#_b(vx) \geq 1$.
	Inoltre affinché $u v^2 w x^2 y \in \mathcal{L}$ sia ancora in $\mathcal{L}$ deve valere che
	\begin{align*}
		v &= a^l \\
		x &= b^l \\
	\end{align*}
	con $1 \leq l \leq m$.
	Altrimenti ripetendo perderemmo la struttura.

	Prendiamo ora
	$$ u v^i w x^i z = a^{m + (i - 1)l}b^{m + (i - 1)l} c^{m + m!} \in \mathcal{L} $$
	scegliendo $i = 1 + \frac{m!}{l}$ otteniamo la stringa 
	$$ \beta = a^{m + m!} b^{m + m!} c^{m + m!} $$
	che appartiene al nostro linguaggio.
	\begin{figure}[H]
		\centering
		\begin{subfigure}{.3\textwidth}
			\centering
			\begin{tikzpicture}[
					PUNTO/.style={minimum size=0, inner sep=0, outer sep=0}, 
					scale=0.45, 
					every node/.style={transform shape}
				]
				\node[PUNTO] at (0, 0) (top-1) {};
				\node[PUNTO] at (0, -2) (top-2) {};

				\node[PUNTO] at (4, -4) (right-1) {};
				\node[PUNTO] at (2, -4) (right-2) {};

				\node[PUNTO] at (-4, -4) (left-1) {};
				\node[PUNTO] at (-2, -4) (left-2) {};

				\node [above=of top-1, yshift=-25pt] {$S$};
				\node [above=of top-2, yshift=-25pt] {$A$};

				\draw[-] (top-1) -- (left-1);
				\draw[-] (right-1) -- (top-1);
				\draw[-] (top-2) -- (left-2);
				\draw[-] (right-2) -- (top-2);
				\draw[-] (left-1) -- (left-2);
				\draw[-] (right-1) -- (right-2);

				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] 
					([yshift=-5pt] left-1.south) to node[below, yshift=-.5cm] {$u = a^+$} ([yshift=-5pt] left-2.south);
				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] 
					([yshift=-5pt] right-2.south) to node[below, yshift=-.5cm] {$y = c^+$} ([yshift=-5pt] right-1.south);
			\end{tikzpicture}
		\end{subfigure}
		\begin{subfigure}{.3\textwidth}
			\centering
			\begin{tikzpicture}[
					PUNTO/.style={minimum size=0, inner sep=0, outer sep=0}, 
					scale=0.45, 
					every node/.style={transform shape}
				]
				\node[PUNTO] at (0, 0) (top-1) {};
				\node[PUNTO] at (0, -2) (top-2) {};

				\node[PUNTO] at (4, -4) (right-1) {};
				\node[PUNTO] at (2, -4) (right-2) {};

				\node[PUNTO] at (-4, -4) (left-1) {};
				\node[PUNTO] at (-2, -4) (left-2) {};

				\node [above=of top-1, yshift=-25pt] {$A$};
				\node [above=of top-2, yshift=-25pt] {$A$};

				\draw[-] (top-1) -- (left-1);
				\draw[-] (right-1) -- (top-1);
				\draw[-] (top-2) -- (left-2);
				\draw[-] (right-2) -- (top-2);
				\draw[-] (left-1) -- (left-2);
				\draw[-] (right-1) -- (right-2);

				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] 
					([yshift=-5pt] left-1.south) to node[below, yshift=-.5cm] {$v = a^i$} ([yshift=-5pt] left-2.south);
				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] 
					([yshift=-5pt] right-2.south) to node[below, yshift=-.5cm] {$x = b^i$} ([yshift=-5pt] right-1.south);
			\end{tikzpicture}
		\end{subfigure}
		\begin{subfigure}{.3\textwidth}
			\centering
			\begin{tikzpicture}[
					PUNTO/.style={minimum size=0, inner sep=0, outer sep=0}, 
					scale=0.45, 
					every node/.style={transform shape}
				]
				\node[PUNTO] at (0, 0) (top-1) {};
				\node[PUNTO] at (0, -2) (top-2) {};

				\node[PUNTO] at (2, -3) (right-1) {};

				\node[PUNTO] at (-2, -3) (left-1) {};

				\node [above=of top-1, yshift=-25pt] {$A$};

				\draw[-] (top-1) -- (left-1);
				\draw[-] (right-1) -- (top-1);
				\draw[-] (left-1) -- (right-1);

				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] 
					([yshift=-5pt] left-1.south) to node[below, yshift=-.5cm] {$w = a^+ b^+$} ([yshift=-5pt] right-1.south);
			\end{tikzpicture}
		\end{subfigure}
	\end{figure}
	% fig 17.4
	Nella stringa $\beta$ la maggior parte delle $b$ è ottenuta replicando il secondo sottoalbero.

	Partiamo invece da una stringa
	$$ z' = a^{m + m!} b^m c^m $$
	e marco tutte le $c$.
	Scomponiamola in
	$$ u' v' w' x' y' $$
	e utilizzando i ragionamenti di prima mostriamo che $v' = b^j$ e $x' = c^j$ e ripetendo $i$ volte $v'$ e $x'$ otteniamo
	$$ a^{m + m!} b^{m + (i - 1)j} c^{m + (i - 1)j} $$
	e scegliendo $i = 1 + \frac{m!}{j}$ come prima otteniamo $\beta$.
	Come prima possiamo immaginare alberi di forma
	% fig 17.5
	\begin{figure}[H]
		\centering
		\begin{subfigure}{.3\textwidth}
			\centering
			\begin{tikzpicture}[
					PUNTO/.style={minimum size=0, inner sep=0, outer sep=0}, 
					scale=0.45, 
					every node/.style={transform shape}
				]
				\node[PUNTO] at (0, 0) (top-1) {};
				\node[PUNTO] at (0, -2) (top-2) {};

				\node[PUNTO] at (4, -4) (right-1) {};
				\node[PUNTO] at (2, -4) (right-2) {};

				\node[PUNTO] at (-4, -4) (left-1) {};
				\node[PUNTO] at (-2, -4) (left-2) {};

				\node [above=of top-1, yshift=-25pt] {$S$};
				\node [above=of top-2, yshift=-25pt] {$A'$};

				\draw[-] (top-1) -- (left-1);
				\draw[-] (right-1) -- (top-1);
				\draw[-] (top-2) -- (left-2);
				\draw[-] (right-2) -- (top-2);
				\draw[-] (left-1) -- (left-2);
				\draw[-] (right-1) -- (right-2);

				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] 
					([yshift=-5pt] left-1.south) to node[below, yshift=-.5cm] {$u' = a^+$} ([yshift=-5pt] left-2.south);
				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] 
					([yshift=-5pt] right-2.south) to node[below, yshift=-.5cm] {$y' = c^+$} ([yshift=-5pt] right-1.south);
			\end{tikzpicture}
		\end{subfigure}
		\begin{subfigure}{.3\textwidth}
			\centering
			\begin{tikzpicture}[
					PUNTO/.style={minimum size=0, inner sep=0, outer sep=0}, 
					scale=0.45, 
					every node/.style={transform shape}
				]
				\node[PUNTO] at (0, 0) (top-1) {};
				\node[PUNTO] at (0, -2) (top-2) {};

				\node[PUNTO] at (4, -4) (right-1) {};
				\node[PUNTO] at (2, -4) (right-2) {};
3
				\node[PUNTO] at (-4, -4) (left-1) {};
				\node[PUNTO] at (-2, -4) (left-2) {};

				\node [above=of top-1, yshift=-25pt] {$A'$};
				\node [above=of top-2, yshift=-25pt] {$A'$};

				\draw[-] (top-1) -- (left-1);
				\draw[-] (right-1) -- (top-1);
				\draw[-] (top-2) -- (left-2);
				\draw[-] (right-2) -- (top-2);
				\draw[-] (left-1) -- (left-2);
				\draw[-] (right-1) -- (right-2);

				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] 
					([yshift=-5pt] left-1.south) to node[below, yshift=-.5cm] {$v' = b^j$} ([yshift=-5pt] left-2.south);
				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] 
					([yshift=-5pt] right-2.south) to node[below, yshift=-.5cm] {$x' = c^j$} ([yshift=-5pt] right-1.south);
			\end{tikzpicture}
		\end{subfigure}
		\begin{subfigure}{.3\textwidth}
			\centering
			\begin{tikzpicture}[
					PUNTO/.style={minimum size=0, inner sep=0, outer sep=0}, 
					scale=0.45, 
					every node/.style={transform shape}
				]
				\node[PUNTO] at (0, 0) (top-1) {};

				\node[PUNTO] at (2, -3) (right-1) {};

				\node[PUNTO] at (-2, -3) (left-1) {};

				\node [above=of top-1, yshift=-25pt] {$A'$};

				\draw[-] (top-1) -- (left-1);
				\draw[-] (right-1) -- (top-1);
				\draw[-] (left-1) -- (right-1);

				\draw[decorate, decoration={brace, mirror, amplitude=0.2cm}] 
					([yshift=-5pt] left-1.south) to node[below, yshift=-.5cm] {$w' = b^+ c^+$} ([yshift=-5pt] right-1.south);
			\end{tikzpicture}
		\end{subfigure}
	\end{figure}
	Qui ancora la maggior parte delle $b$ è generata dal secondo albero.
	Ma visto che l'albero di $A$ genera anche $a$ e l'albero di $A'$ genera anche $c$ i due sono per forza diversi.
\end{proof}

Possiamo dare una definizione analoga di ambiguità per gli automi a pila.
\begin{definizione}
	Un PDA è ambiguo se esiste una stringa con due computazioni accettanti differenti.
\end{definizione}
\`E facile vedere attraverso la trasformazione da grammatica ad automa che il numero di computazioni diverse è uguale al numero di alberi leftmost diversi, visto che si simulava la derivazione leftmost.
Dal lato opposto è più difficile da mostrare e soprattutto la trasformazione non preserva il grado di ambiguità.
\begin{figure}[H]
	\centering
	\begin{tikzpicture}
		\draw[->] (-1, 0) -- (-1, 4) node[left, yshift=-0.2cm] {\rotatebox{90}{\tiny pila}};
		\draw[->] (-1, 0) -- (7, 0) node[below, xshift=-0.2cm] {\tiny input};

		\node at (0, 0) [circle,fill,inner sep=1.5pt] {};
		\node at (1.5, 0) [circle,fill,inner sep=1.5pt] {};
		\node at (3, 0) [circle,fill,inner sep=1.5pt] {};
		\node at (4.5, 0) [circle,fill,inner sep=1.5pt] {};
		\node at (6, 0) [circle,fill,inner sep=1.5pt] {};

		\tikzmath {
			real \x, \rand, \precx, \precy;
			\precx = 0;
			\precy = 0;
			for \x in {0.2,0.4,...,1.3} {
				\rand = 1 + (random(0, 100) / 66);
				{ \draw[-] (\precx, \precy) -- (\x, \rand); };
				\precx = \x;
				\precy = \rand;
			};
			{ \draw[-] (\precx, \precy) -- (1.5, 0); };
			\precx = 1.5;
			\precy = 0;
			for \x in {1.7,1.9,...,2.8} {
				\rand = 1 + (random(0, 100) / 66);
				{ \draw[-] (\precx, \precy) -- (\x, \rand); };
				\precx = \x;
				\precy = \rand;
			};
			{ \draw[-] (\precx, \precy) -- (3, 0); };
			\precx = 3;
			\precy = 0;
			for \x in {3.2,3.4,...,4.3} {
				\rand = 1 + (random(0, 100) / 66);
				{ \draw[-] (\precx, \precy) -- (\x, \rand); };
				\precx = \x;
				\precy = \rand;
			};
			{ \draw[-] (\precx, \precy) -- (4.5, 0); };
			\precx = 4.5;
			\precy = 0;
			for \x in {4.7,4.9,...,5.8} {
				\rand = 1 + (random(0, 100) / 66);
				{ \draw[-] (\precx, \precy) -- (\x, \rand); };
				\precx = \x;
				\precy = \rand;
			};
			{ \draw[-] (\precx, \precy) -- (6, 0); };
		}
	\end{tikzpicture}
\end{figure}
Si può vedere dal grafico infatti che la pila può essere scomposta in vari modi equivalenti ($1(2(34))$, $(12)(34)$, $(((1)2)3)4$, e così via). % chiarisco meglio
Quindi parlare di ambiguità negli automi a pila e nelle grammatiche di tipo 2 è equivalente.
E di conseguenza un linguaggio inerentemente ambiguo avrà sia grammatica che automa a pila ambigui.

Perché un automa a pila ammetta ambiguità questo deve per forza essere nondeterministico.
Quindi
$$ \mathcal{L} = \{ a^p b^q c^r \mid p = q \vee q = r \} $$
necessita il nondeterminismo.

Richiamiamo la definizione di automa a pila deterministico:
$$ M = \langle Q, \Sigma, \Gamma, \delta, q_0, Z_0, F \rangle $$
è deterministico se ad ogni passo possiamo fare una singola scelta, cioè sse
\begin{itemize}
	\item $\forall q \in Q, A \in \Gamma \mid \delta(q, \varepsilon, A) \neq \varnothing \Rightarrow \forall a \in \Sigma \delta(q, a, A) = \varnothing $
	\item $\forall q \in Q, A \in \Gamma, a \in \Sigma \cup \{ \varepsilon \} \mid | \delta(q, a, A) | = 1 $
\end{itemize}
mostriamo ora che i due criteri di accettazione sono diversi per automi deterministici, specificamente la accettazione per pila vuota è più debole.
Supponiamo infatti di avere un automa a pila che accetta per pila vuota il linguaggio regolare $(aa)^+$.
Siccome l'automa deve accettare $aa$ dopo questa avrà la pila vuota.
Ma da una pila vuota non può più continuare, quindi non può accettare $aaaa$ ad esempio.
Quindi i linguaggi che accetta sono tutti quelli le cui stringhe non hanno come prefissi altre stringhe del linguaggio, perché nel riconoscere il prefisso svuoterà la pila e non potrà più andare avanti.
Questi in teoria dei codici sono detti codici prefissi e contengono alcuni regolari e alcuni context free.

Di solito si ovvia a questo utilizzando un simbolo finale non nel linguaggio, ad esempio $(aa)^+ \#$, in modo tale che la pila non si svuoti completamente prima di arrivare al marcatore finale.

Quindi da ora in poi quando parliamo di DCFL, cioè i linguaggi CF deterministici, intendiamo i linguaggi riconosciuti per stati finali.
Questi contengono per forza i linguaggi regolari, perché semplicemente possiamo non utilizzare la pila.
Vale che
$$ \text{Reg} \subset \text{DCFL} \subset \text{CFL} $$
perché $\{ a^p b^q c^r \mid p = q \vee q = r \} \in \text{CFL}$ ma $\not \in \text{DCFL}$.

Abbiamo visto che l'ambiguità necessità del nondeterminismo.
Possiamo chiederci l'inverso, cioè se un linguaggio necessita del nondeterminismo allora questo è per forza ambiguo.
Un linguaggio che necessita del nondeterminismo è quello dei palindromi (non ancora dimostrato), o -- per semplicità -- dei palindromi pari
$$ L = \{ w w^R \mid w \in \{a, b\}^* \} $$
L'automa deve ``scommettere'' su quando è arrivato a metà , quindi il nondeterminismo è necessario, ma la metà è una sola, qiundi non è ambiguo.
\`E anche facile vederlo dalla grammatica che è
	$$ S \rightarrow a S a \mid b S b \mid \varepsilon $$
Quindi il nondeterminismo non implica la ambiguità.

Non studieremo il determinismo per le grammatiche perché questo è più strano e ammette miriadi di classi diverse.

\section{Operazioni e chiusura con i linguaggi CF}
\begin{table}[H]
	\centering
	\begin{longtblr}[
			note{1} = {Risultati non mostrati a lezione},
			caption = Chiusura delle opreazioni,
			entry = none
		]{ colspec = {|c|c|c|}}
		\hline
		Operazione & CFL? & DCFL? \\
		\hline
		Unione & Sì & No \\
		\hline
		Intersezione & No & No \\
		\hline
		Intersezione con un regolare & Sì & Sì \\
		\hline
		Complemento & No & Sì \\
		\hline
		Prodotto & Sì & No \\
		\hline
		Chiusura di Kleene & Sì & No \\
		\hline
		Morfismo & Sì & No \\
		\hline
		Sostituzione & Sì & No \\
		\hline
		Reversal\TblrNote{1} & Sì & No \\	% idk l'ha detto e basta
		\hline
		Shuffle\TblrNote{1} & No & No  \\	% idk l'ha detto e basta
		\hline
	\end{longtblr}
\end{table}

\paragraph{Unione} Date due grammatiche $G' = \langle V', \Sigma, P', S' \rangle$ e $G'' = \langle V'', \Sigma, P'', S'' \rangle$ con $V' \cap V'' = \varnothing$, definiamo la unione delle due come 
$$ G = \langle V' \cup V'' \cup \{ S \}, \Sigma, P' \cup P'' \cup \{ S \rightarrow S', S \rightarrow S'' \}, S \rangle $$
e nel caso degli automi possiamo fare la scelta all'inizio.
La unione è chiusa per i CFL e non chiusa per i CDFL, infatti dati $L' = \{ a^n b^n c^m \} \in \text{DCFL}$ e $L'' = \{ a^m b^n c^n \} \in \text{DCFL}$ la loro unione $L' \cup L'' = \{ a^p b^q c^r \mid p = q \vee q = r \}$ è ambigua, quindi nondeterministica.

\paragraph{Intersezione} La intersezione non è chiusa, infatti $L' \cap L'' = \{ a^n b^n c^n \}$ che abbiamo dimostrato che non è CF.
Inoltre non possiamo utilizzare il metodo dei FSA di far andare in parallelo i due automi, qui i due due automi interferirebbero nel loro utilizzo della pila.

\paragraph{Intersezione con un regolare} Possiamo usare il metodo degli FSA di far andare in parallelo i due automi, quindi incorporo nel controllo del PDA l'FSA.

\paragraph{Complemento} Se il complemento fosse chiuso, potremmo ottenere una intersezione chiusa attraverso l'unione e De Morgan, quindi il complemento deve per forza non essere chiuso.
Il complemento per i deterministici invece è chiuso.
% lezione 18
\begin{tcolorbox}[breakable]
	Esibiamo ora un controesempio che mostra che il complemento non è chiuso rispetto ai CF.
	Prendiamo il linguaggio
	$$ L = \{ x \in \{a, b\}^* \mid \forall w : x \neq w w \} \in \text{CF} $$
	il complemento di questo è
	$$ L^C = \{ w w \mid w \in \{a, b\}^* \} $$
	che come abbiamo già mostrato in passato non è context free.	% ci dovrebbe essere un esercizio in cui mostriamo che il linguaggio L è CF

	Per completezza mostriamo anche che $L$ sia effettivamente CF costruendo un automa a pila che lo riconosce.
	Questo -- molto brevemente -- scommette sulla posizione dei due caratteri diversi.
	\begin{center}
		\begin{tikzpicture}[
				PUNTO/.style={minimum size=0, inner sep=0, outer sep=0}, 
			]
			\node[PUNTO] at (0, 0) (left) {};
			\node[PUNTO] at (4, 0) (middle) {};
			\node[PUNTO] at (8, 0) (right) {};

			\node[PUNTO, label=below:{\tiny $i$}] at (1, 0) (i) {};
			\node[PUNTO, label=below:{\tiny $i + n$}] at (5, 0) (in) {};

			\draw (i) circle[radius=2pt];
			\draw (in) circle[radius=2pt];

			\draw[|-|] (left) -- node {\tiny $|$} (right);

			\draw[decorate, decoration={brace, mirror, amplitude=.2cm}] ([yshift=-.35cm]left.south) to node[below, yshift=-.2cm] {\tiny $n'$} ([yshift=-.35cm]i.south);
			\draw[decorate, decoration={brace, mirror, amplitude=.2cm}] ([yshift=-.35cm]i.south) to node[below, yshift=-.2cm] {\tiny $n$} ([yshift=-.35cm]in.south);
			\draw[decorate, decoration={brace, mirror, amplitude=.2cm}] ([yshift=-.35cm]in.south) to node[below, yshift=-.2cm] {\tiny $n''$} ([yshift=-.35cm]right.south);
			\draw[decorate, decoration={brace, amplitude=.2cm}] ([yshift=.2cm]left.north) to node[above, yshift=.2cm] {\tiny $n$} ([yshift=.2cm]middle.north);
			\draw[decorate, decoration={brace, amplitude=.2cm}] ([yshift=.2cm]middle.north) to node[above, yshift=.2cm] {\tiny $n$} ([yshift=.2cm]right.north);
		\end{tikzpicture}
	\end{center}
	con $n' + n'' = n$ e $w_i \neq w_{i + n}$.
	Più precisamete l'automa segue le seguenti fasi
	\begin{enumerate}
		\item sulla pila viene contato $n'$.
		\item si sceglie nondeterministicamente un terminale $\sigma$ e si iniziano a togliere i $n'$ simboli accumulati finché non si svuota la pila.
		\item a questo punto si ricomincia a contare sulla pila fino a che non si sceglie un secondo terminale $\rho$ che deve essere differente.
		\item si ricomincia a togliere i simboli $n''$ dalla pila consumando l'input
		\item deve valere che alla fine dell'input sia vuota anche la pila e viceversa, affinché $n' + n'' = n$
	\end{enumerate}
\end{tcolorbox}

\begin{lemma}
	I DCFL sono chiusi rispetto al complemento.
\end{lemma}
Uno dei problemi con gli automi a pila è che questi possono non terminare.
Infatti utillizzando le $\varepsilon$-mosse l'automa può continuare a far oscillare la pila o far crescere la pila all'infinito.
Visto però che gli stati e i simboli della pila sono finiti, data una configurazione di superficie (\textit{surface configuration}, o lo stato e il simbolo in cima alla pila) capire se ci sarà un ciclo infinito è decidibile, e consiste banalmente nel controllare se lo stesso stato e simbolo di pila si ripetono senza consumare input.

Inoltre visto che sono ammesse le $\varepsilon$-mosse, in un automa che accetta per stato finale, può accadere che una volta che l'input è finito l'automa continui a fare mosse, e addirittura può finire in un ciclo infinito.
In ogni caso se c'è almeno uno stato finale tra quelli che visita dopo la fine dell'input, allora l'input è accettato.

\begin{lemma}
	Supponiamo che
	$$ M = \langle Q, \Sigma, \Gamma, \delta, q_0, Z_0, F \rangle $$
	sia un automa a pila deterministico.
	Costruiamo 
	$$ M' = \langle Q', \Sigma, \Gamma', \delta', q_0', X_0, F' \rangle $$
	tale che
	$$ L(M) = L(M') $$
	ed $M'$ scandisce sempre l'intero input.
\end{lemma}
\begin{proof}
	Definiamo l'automa $M'$ tale che
	\begin{itemize}
		\item $Q' = Q \cup \{q_0', d, f \}$, con $d$ detto \textit{stato trappola}
		\item $\Gamma' = \Gamma \cup \{X_0\} $
		\item $F' = F \cup \{ f \} $
	\end{itemize}
	e definiamo le mosse che fa l'automa
	\begin{itemize}
		\item $\delta'(q_0', \varepsilon, X_0) = (q_0, Z_0X_0)$, cioè -- come in altre costruzioni -- ``infiliamo'' in fondo alla pila un nostro simbolo.
			Questo è necessario perché la prossima mossa potrebbe non essere definita perché si è svuotata la pila.
		\item mostriamo ora alcune regole particolari che portano allo stato trappola
			\begin{itemize}
				\item se in una certa configurazione di superficie dell'automa $M$ non esiste una prossima mossa definita, cioè se
					$$\delta(q, a, X) = \delta(q, \varepsilon, X) = \varnothing, \hspace{1cm} q \in Q, a \in \Sigma, X \in \Gamma$$
					allora nell'automa $M'$ finisco nello stato trappola
					$$\delta'(q, a, X) = (d, X)$$
				\item se nell'automa $M$ la pila si è svuotata e non potrei pià fare mosse nell'automa $M'$ finisco nello stato trappola
					$$\delta'(q, a, X_0) = (d, X_0),\hspace{1cm}q \in Q', a \in \Sigma$$
				\item nello stato trappola consumo l'input e rimango nello stato trappola
					$$\delta'(d, a, X) = (d, X),\hspace{1cm}a \in \Sigma, X \in \Gamma'$$
				\item se da $(q, X)$, con $q \in Q$ e $X \in \Gamma$ è possibile un loop di $\varepsilon$-mosse
					$$\delta'(q, \varepsilon, X) = 
					\begin{cases}
						(d, X) & \text{se il loop non visita stati finali} \\
						(f, X) & \text{altrimenti}
					\end{cases}
					$$
				\item se sono nello stato finale $f$ e posso ancora leggere input, allora non sono alla fine quindi mi sposto nello stato trappola
					$$\delta'(f, a, X) = (d, X), \hspace{1cm}a \in \Sigma, X \in \Gamma'$$
			\end{itemize}
		\item in tutti gli altri casi $\delta'(q, a, X) = \delta(q, a, X)$ con $q \in Q, a \in \Sigma \cup \{\varepsilon\}, X \in \Gamma$
	\end{itemize}
\end{proof}

\begin{proof}[Automa per il complemento]
Sia 
$$ M = \langle Q, \Sigma, \Gamma, \delta, q_0, Z_0, F \rangle $$
un DPDA che accetta $L$ e scandisce sempre l'intero input.
Costruiamo l'automa per il complemento
$$ M' = \langle Q', \Sigma, \Gamma, \delta', q_0', Z_0, F' \rangle $$
con 
\begin{itemize}
	\item $Q' = Q \times \{y, n, A \}$, dove $y, n, A$ servono a ricordare se nell'ultima sequenza di $\varepsilon$-mosse ho visto uno stato finale, rispettivamente:
		\begin{itemize}
			\item $y$ indica che nell'attuale stato della sequenza di $\varepsilon$-mosse è stato visitato uno stato finale.
			\item $n$ indica che nell'attuale stato della sequenza di $\varepsilon$-mosse non è stato visitato uno stato finale.
			\item $A$ indica che non ho visitato uno stato finale e non posso fare alcuna mossa.
		\end{itemize}
	\item $F' = Q \times \{ A \}$, cioè tutti gli stati in cui non posso procedere e non ho visitato uno stato finale
\end{itemize}
Definiamo ora $\delta'$ come
\begin{itemize}
	\item se $\delta(q, \varepsilon, X) = (p, \gamma)$ allora 
		\begin{itemize}
			\item $\delta'([q, y], \varepsilon, X) = ([p, y], \gamma)$, quindi se in passato ho visitato uno stato finale, continuo a ricordare che ho visitato uno stato finale.
			\item se non ho ancora visto uno stato finale, e il prossimo lo è, cambio $n$ a $y$ 
				$$\delta'([q, n], \varepsilon, X) = \begin{cases} ([p, n], \gamma) & \text{se } p \not \in F \\ ([p, y], \gamma) & \text{se } p \in F \end{cases}$$
		\end{itemize}
	\item se $\delta(q, a, X) = (p, \gamma)$ con $a \in \Sigma$, allora
		\begin{itemize}
			\item se ero in uno stato $y$ e consumo dell'input e finisco in uno stato non finale, cambio $y$ a $n$
				$$\delta'([q, y], a, X) = \begin{cases} ([p, n], \gamma) & \text{se } p \not \in F \\ ([p, y], \gamma) & \text{se } p \in F \end{cases}$$
			\item alternativametne se ero in uno stato $n$ spezzo la mossa in due parti
				\begin{align*}
					\delta'([q, n], \varepsilon, X) &= ([q, A], X) \\
					\delta'([q, A], a, X) &= \begin{cases} ([p, n], \gamma) & \text{se } p \not \in F \\ ([p, y], \gamma) & \text{se } p \in F \end{cases}
				\end{align*}
				cioè prima di consumare dell'input assumo di aver finito la stringa senza esser passato per stati finali nella sequenza di $\varepsilon$-mosse.
				Se c'è ancora in input trasformo lo $A$ in $y$ o $n$.
		\end{itemize}
\end{itemize}
Infine definiamo
$$ q_0' = \begin{cases} [q_0, n] & \text{se } q_0 \not \in F \\ [q_0, y] & \text{se } q_0 \in F \end{cases} $$
\end{proof}

Dalla costruzione di sopra si vede che le $\varepsilon$-mosse sono molto fastidiose.
Come abbiamo visto attraverso la trasformazione in GNF nel caso di PDA si può fare a meno delle $\varepsilon$-mosse a patto di sacrificare la parola vuota.
Lo stesso non vale nel caso di DPDA, e senza $\varepsilon$-mosse otteniamo un modello meno potente.

Dai linguaggi 
\begin{align*}
	L' &= \{ a^i b^j c^k \mid i = j \} \\
	L'' &= \{ a^i b^j c^k \mid j = k \}
\end{align*}
Definiamo il linguaggio 
$$ L_0 = L' \cup dL'' \in DCFL $$
in base a se la stringa inizia con una $d$ o no sappiamo se dobbiamo riconoscere una parola di $L'$ o di $L''$.

\paragraph{Prodotto} Non deterministicamente quando un automa arriva in fondo faccio partire l'automa successivo.
Questo si può fare anche in termini di grammatiche, date $G' = \langle V', \Sigma, P', S' \rangle$ e $G'' = \langle V'', \Sigma, P'', S'' \rangle$ con $V' \cap V'' = \varnothing$ creiamo
$$ G = \langle V' \cup V'' \cup \{ S \}, \Sigma, P' \cup P'' \cup \{ S \rightarrow S' S'' \}, S \rangle $$
Per il caso deterministico utilizziamo $L_0$ di prima % ref
e definiamo
$$ L' = \{ \varepsilon, d \} \cdot L_0 = \{ d^s a^i b^j c^k \mid 0 \leq s \leq 2 \} $$
con 
$$\begin{cases} s = 0 & i = j \\ s = 2 & j = k \\ s = 1 & i = j \vee j = k \end{cases}\} $$
Per mostrare che è ambiguo prendiamo
$$ L' \cap d a^* b^* c^* = \{ d a^i b^j c^k \mid i = j \vee j = k \} \not \in \text{DCFL}$$
con $d a^* b^* c^*$ regolare, visto che i deterministici sono chiusi rispetto all'intersezione con regolari, $L'$ non può essere deterministico.
Inoltre $\{\varepsilon, d\}$ è finito, quindi non solo i linguaggi deterministici non sono chiusi rispetto al prodotto, ma non sono chiusi neanche rispetto al prodotto a sinistra con linguaggi finiti.

Si può mostrare però che i DCFL sono chiusi rispetto al prodotto a destra con regolari, cioè dati $L \in \text{DCFL}$ e $R \in \text{Reg}$ il prodotto $L \cdot R \in \text{DCFL}$.
Questa costruzione è simile al prodotto per gli automi a stati finiti.

\paragraph{Chiusura di Kleene -- star} Questo costruzione è molto simile al prodotto. 
Data la grammatica $G' = \langle V', \Sigma, P', S' \rangle$, costruiamo
$$ G = \langle V' \cup \{ S \}, \Sigma, P' \cup \{ S \rightarrow \varepsilon, S \rightarrow S' S \}, S \rangle $$
Nel caso dei deterministici prendiamo ancora $L_0$ e analizziamo
$$ L_0^* \cap d a^* b^* c^* = d (L_1 \cup L_2) $$
infatti questo ha stringhe della forma
$$ da^ib^jc^k $$
tali che
\begin{itemize}
	\item $dL_2$, per cui $j = k$
	\item o il prodotto $d \in L_2$ per $a^i b^j c^j \in L_1$, per cui $i = j$
\end{itemize}
ma questo abbiamo visto che non è deterministico, quindi $L_0^*$ non è chiuso rispetto alla star.

\paragraph{Morfismo} Per ogni terminale $a \in \Sigma$, lo sostituisco con una stringa $w \in \Delta^*$ utilizzando una funzione
$$ h : \Sigma \rightarrow \Delta^* $$
Per questo basta sostituire i terminali in ogni produzione.

Nel caso dei deterministici  prendiamo 
\begin{align*}
	L' &= \{ a^i b^j c^k \mid i = j \} \\
	L'' &= \{ a^i b^j c^k \mid j = k \} 
\end{align*}
e sappiamo che $L', L'' \in \text{DCFL}$, e che $L' \cup L'' \not \in \text{DCFL}$.
Mentre vale che $L_0 = L' \cup dL'' \in \text{DCFL}$.
Prendiamo il morfismo
$$ h(\sigma) = \begin{cases} \sigma & \text{se } \sigma \neq d \\ \varepsilon & \text{altrimenti} \end{cases} $$
vale che $h(L_0) = L' \cup L'' \not \in \text{DCFL}$, quindi i determinisici non sono chiusi rispetto al morfismo.

\paragraph{Sostituzione} Ad ogni terminale associamo un linguaggio, utilizzando una funzione
$$ s : \Sigma \rightarrow 2^{\Delta^*} $$
Se $L \in \text{CFL}$ e $\forall a \in \Sigma \mid s(a) \in \text{CFL}$, allora $s(L) \in \text{CFL}$.
Molto ad alto livello ad ogni terminale corrisponde una grammatica, nelle produzioni sostituiamo ai terminali l'assioma della grammatica.

Visto che il morfismo è un caso particolare della sostituzione, i determinisitici non sono chiusi rispetto alla sostituzione.

 
\end{document}
